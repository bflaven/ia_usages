{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USECASE_1 : sentiment analysis des commentaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **C'est le usecase_1, voir le ticket IA-38 :**\n",
    "\n",
    "`https://francemm.atlassian.net/browse/IA-38`\n",
    "\n",
    "- **Tous les fichiers sont dans le répertoire  :** \n",
    "\n",
    "`https://github.com/FranceMediasMonde/den-ia/dera/usecase_1_sentiment_analysis`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Collection ou réception et exploration des CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      dim1                                               dim2  \\\n",
      "0      16/01/2024 17:43:16  🇧🇫🇲🇷 La Burkina Faso a obtenu la victoire de j...   \n",
      "1      16/01/2024 17:43:16  🇧🇫🇲🇷 La Burkina Faso a obtenu la victoire de j...   \n",
      "2      16/01/2024 17:43:16  🇧🇫🇲🇷 La Burkina Faso a obtenu la victoire de j...   \n",
      "3      16/01/2024 17:43:16  🇧🇫🇲🇷 La Burkina Faso a obtenu la victoire de j...   \n",
      "4      16/01/2024 17:43:16  🇧🇫🇲🇷 La Burkina Faso a obtenu la victoire de j...   \n",
      "...                    ...                                                ...   \n",
      "15887  25/01/2024 14:45:04  Alors que la sécheresse rend l'accès à l'eau d...   \n",
      "15888  25/01/2024 15:15:02  Si officiellement, ces réfugiés doivent partir...   \n",
      "15889  25/01/2024 15:15:02  Si officiellement, ces réfugiés doivent partir...   \n",
      "15890  25/01/2024 15:15:02  Si officiellement, ces réfugiés doivent partir...   \n",
      "15891  25/01/2024 15:15:02  Si officiellement, ces réfugiés doivent partir...   \n",
      "\n",
      "                                                 message  \n",
      "0      Ce qu'il faut retenir de cette CAN , c'est qu'...  \n",
      "1               Yaam né wend ti yaa la Burkina Faso 😁RFI  \n",
      "2       La Burkina Faso même ?? Pardon le Burkina Faso 🙏  \n",
      "3      Cette victoire est dédié au président Ibrahim ...  \n",
      "4                                   Burkina Faso 🇧🇫🇧🇫🐎💪💪  \n",
      "...                                                  ...  \n",
      "15887        Vive le Maroc 🇲🇦, vive la Côte d'ivoire 🇨🇮.  \n",
      "15888  Donc ce pays échoue la CAN hier et aujourd'hui...  \n",
      "15889  J'appuie cette décision, c'est ce que les pays...  \n",
      "15890  Gaïus Alvinius Quel rapport ? Tout ne tourne p...  \n",
      "15891  Les Africains devraient se sentir libres de re...  \n",
      "\n",
      "[15892 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "CSV_SOURCE=\"data_source/source_quintly_commentaires_0.csv\"\n",
    "# Load the dataframe from CSV\n",
    "df = pd.read_csv(CSV_SOURCE)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Preparation ou \"nettoyage\" des CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dans la phase de préparation, il faut souvent diminuer la taille des fichiers tout est expliqué dans le fichier `001_split_files.py`**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      dim1                                               dim2  \\\n",
      "0      16/01/2024 17:43:16  🇧🇫🇲🇷 La Burkina Faso a obtenu la victoire de j...   \n",
      "1      16/01/2024 17:43:16  🇧🇫🇲🇷 La Burkina Faso a obtenu la victoire de j...   \n",
      "2      16/01/2024 17:43:16  🇧🇫🇲🇷 La Burkina Faso a obtenu la victoire de j...   \n",
      "3      16/01/2024 17:43:16  🇧🇫🇲🇷 La Burkina Faso a obtenu la victoire de j...   \n",
      "4      16/01/2024 17:43:16  🇧🇫🇲🇷 La Burkina Faso a obtenu la victoire de j...   \n",
      "...                    ...                                                ...   \n",
      "15887  25/01/2024 14:45:04  Alors que la sécheresse rend l'accès à l'eau d...   \n",
      "15888  25/01/2024 15:15:02  Si officiellement, ces réfugiés doivent partir...   \n",
      "15889  25/01/2024 15:15:02  Si officiellement, ces réfugiés doivent partir...   \n",
      "15890  25/01/2024 15:15:02  Si officiellement, ces réfugiés doivent partir...   \n",
      "15891  25/01/2024 15:15:02  Si officiellement, ces réfugiés doivent partir...   \n",
      "\n",
      "                                                 message  \n",
      "0      Ce qu'il faut retenir de cette CAN , c'est qu'...  \n",
      "1               Yaam né wend ti yaa la Burkina Faso 😁RFI  \n",
      "2       La Burkina Faso même ?? Pardon le Burkina Faso 🙏  \n",
      "3      Cette victoire est dédié au président Ibrahim ...  \n",
      "4                                   Burkina Faso 🇧🇫🇧🇫🐎💪💪  \n",
      "...                                                  ...  \n",
      "15887        Vive le Maroc 🇲🇦, vive la Côte d'ivoire 🇨🇮.  \n",
      "15888  Donc ce pays échoue la CAN hier et aujourd'hui...  \n",
      "15889  J'appuie cette décision, c'est ce que les pays...  \n",
      "15890  Gaïus Alvinius Quel rapport ? Tout ne tourne p...  \n",
      "15891  Les Africains devraient se sentir libres de re...  \n",
      "\n",
      "[15892 rows x 3 columns]\n",
      "the file data_split/source_quintly_commentaires_sample_1.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_2.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_3.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_4.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_5.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_6.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_7.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_8.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_9.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_10.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_11.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_12.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_13.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_14.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_15.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_16.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_17.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_18.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_19.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_20.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_21.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_22.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_23.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_24.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_25.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_26.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_27.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_28.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_29.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_30.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_31.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_32.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_33.csv has been created\n",
      "the file data_split/source_quintly_commentaires_sample_34.csv has been created\n",
      "\n",
      "--- DONE\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "[env]\n",
    "# Conda Environment\n",
    "conda create --name sentiment_analysis python=3.9.13\n",
    "conda info --envs\n",
    "source activate sentiment_analysis\n",
    "conda deactivate\n",
    "\n",
    "# if needed to remove\n",
    "conda env remove -n [NAME_OF_THE_CONDA_ENVIRONMENT]\n",
    "\n",
    "# update conda \n",
    "conda update -n base -c defaults conda\n",
    "\n",
    "# to export requirements\n",
    "pip freeze > requirements.txt\n",
    "\n",
    "# to install\n",
    "pip install -r requirements.txt\n",
    "\n",
    "\n",
    "# [path]\n",
    "cd /Users/brunoflaven/Documents/02_copy/DERA_Ghislain_USECASES/dera-usecases/usecase_1_sentiment_analysis\n",
    "\n",
    "# LAUNCH the file\n",
    "python 001_split_files.py\n",
    "\n",
    "\n",
    "[install]\n",
    "python -m pip install transformers\n",
    "python -m pip install pyarrow\n",
    "python -m pip install pandas\n",
    "python -m pip install numpy\n",
    "python -m pip install tensorflow\n",
    "python -m pip install sentencepiece\n",
    "\n",
    "[source]\n",
    "https://huggingface.co/cmarkea/distilcamembert-base-sentiment\n",
    "\n",
    "The dataset comprises 204,993 reviews for training and 4,999 reviews for the test from Amazon, and 235,516 and 4,729 critics from Allocine website. The dataset is labeled into five categories:\n",
    "\n",
    "\n",
    "1 étoile : représente une appréciation terrible,\n",
    "2 étoiles : mauvaise appréciation,\n",
    "3 étoiles : appréciation neutre,\n",
    "4 étoiles : bonne appréciation,\n",
    "5 étoiles : excellente appréciation.\n",
    "\n",
    "1 star: represents a terrible appreciation,\n",
    "2 stars: bad appreciation,\n",
    "3 stars: neutral appreciation,\n",
    "4 stars: good appreciation,\n",
    "5 stars: excellent appreciation.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# DATA\n",
    "import numpy as np  # Importing numpy library and aliasing it as np\n",
    "import pandas as pd  # Importing pandas library and aliasing it as pd\n",
    "\n",
    "##### VALUES\n",
    "CSV_SOURCE=\"data_source/source_quintly_commentaires_0.csv\"  # Assigning a file path to CSV_SOURCE variable\n",
    "\n",
    "# 33 047 rows ~ 34 000 so split in 34 files with 1000 rows\n",
    "\n",
    "# Reading the data from CSV_SOURCE file into a pandas DataFrame\n",
    "data = pd.read_csv(CSV_SOURCE)\n",
    "print(data)  # Printing the DataFrame to the console\n",
    "\n",
    "# Define the number of CSV files to split the data into\n",
    "k = 34\n",
    "# Define the size of each split\n",
    "size = 1000\n",
    "\n",
    "# Loop to split the data into k files\n",
    "for i in range(k):\n",
    "    # Slicing the DataFrame to select rows for the current split\n",
    "    df = data[size*i:size*(i+1)]\n",
    "    # Writing the selected rows to a new CSV file with a unique name\n",
    "    df.to_csv(f'data_split/source_quintly_commentaires_sample_{i+1}.csv', index=False)\n",
    "    # Printing a message indicating that the file has been created\n",
    "    print (f'the file data_split/source_quintly_commentaires_sample_{i+1}.csv has been created')\n",
    "\n",
    "print('\\n--- DONE')  # Printing a message indicating that the splitting process is done\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature Engineering and Modelling ou choix du modele de ML (machine learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dans la phase de modeling, il faut souvent sélectionner le meilleure modèle et itérer pour voir si la prédiction est bonne. Dans la cas du sentiment analysis, c’est un problème connu, la seule difficulté est de trouvé un modèle qui a été entraîné sur la langue en l’espèce le français. Tout est expliqué dans le fichier `002_sentiment_analysis.py`**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATTENTION il faut s’assurer que les fichiers source .csv existent dans le bon répertoire et que le répertoire de destination existe c'est à dire que architecture du projet et la même\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data Preparation ou \"recontruction\" des CSV pour un export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment_analysis",
   "language": "python",
   "name": "sentiment_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
