# ia_spacy_llm.md

## Intro
An article exploring the process for testing the output of Large Language Models (LLMs) using a tool called "promptfoo." This tool allows developers to evaluate the quality and relevance of LLM outputs by defining tests for both structural and content-based criteria. It outlines a scenario where "promptfoo" is used to test the validity of JSON outputs and the quality of generated text summaries, emphasizing its utility in ensuring reliable LLM performance for applications. It also highlights the benefits of "promptfoo," including its developer-friendly nature, battle-tested reliability, and open-source availability, making it a powerful tool for enhancing LLM-based applications.

**You can read the article on my blog**
[Promptfoo: The Ultimate Tool for Ensuring LLM Quality and Reliability](https://wp.me/p3Vuhl-3me)



## Audio version
This post is also an experiment to test NotebookLM. So, here is this regular blog post "Promptfoo: The Ultimate Tool for Ensuring LLM Quality and Reliability" converted into a podcast using NotebookLM.

[Blog Post Audio made with NotebookLM on Promptfoo](https://on.soundcloud.com/vmw6Aj1S6Nx5AT8V6)

# videos

[Promptfoo: The Ultimate Tool for Ensuring LLM Quality and Reliability (Part 1)](https://www.youtube.com/watch?v=hFh_DkN63KU)[![Promptfoo: The Ultimate Tool for Ensuring LLM Quality and Reliability (Part 1)](testing_llm_with_promptfoo_1.png)](https://www.youtube.com/watch?v=hFh_DkN63KU)



[Promptfoo: The Ultimate Tool for Ensuring LLM Quality and Reliability (Part 2)](https://www.youtube.com/watch?v=ZRuqwKowBWI)[![Promptfoo: The Ultimate Tool for Ensuring LLM Quality and Reliability (Part 2)](testing_llm_with_promptfoo_2.png)](https://www.youtube.com/watch?v=ZRuqwKowBWI)
