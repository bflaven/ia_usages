[
    {
        "id": 12815,
        "link": "https:\/\/flaven.fr\/2024\/05\/unraveling-the-cost-of-ai-the-hidden-expenses-of-api-keys-and-pay-as-you-go-pricing-in-ai-based-products\/",
        "title": {
            "rendered": "Unraveling the Cost of AI: The Hidden Expenses of API Keys and Pay-as-You-Go Pricing in AI-Based Products"
        },
        "content": {
            "rendered": "<p>&#8220;After all, we are not communist&#8221; says Emilio &#8220;The Wolf&#8221; Barzini in the Godafather* and indeed despite the virtuous storytelling, IA is here to make money and to make a lot&#8230; <\/p>\n<p><b>For this post, you can find all files, mostly prompts, on my GitHub account. See <a href=\"https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ai_pricing_llm\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ai_pricing_llm<\/a><\/b><\/p>\n<p><i>* I watched Coppola&#8217;s The Godfather once again which is, in addition to being a great film about the Italian American mafia, a great lesson on capitalism and team management! <\/i><\/p>\n<p>More seriously, as the PO of an AI-based product, the question of price quickly arises. I&#8217;m not talking about any development costs but much more the price of an API key and its use via prompts. Indeed, IA companies are not philanthropists, and their economic models are based on addiction. Without paying attention, the pay-as-you-go pricing system can quickly become &#8220;poisonous&#8221; as the more you outsource tasks to IA, the more you pay.<\/p>\n<p>For the last week, I have decided to go with ChatGPT and Mistral API key, so I was forced to scrutinize the pricing pages for input and output according to the models. Here is the ressources: <\/p>\n<ol>\n<lI>The precise prices of the ChatGPT API: <a href=\"https:\/\/openai.com\/api\/pricing\" target=\"_blank\" rel=\"noopener\">https:\/\/openai.com\/api\/pricing<\/a><\/p>\n<\/li>\n<li>The precise prices of the Mistral API see the Pay as you Go section: <a href=\"https:\/\/mistral.ai\/fr\/technology\/#models\" target=\"_blank\" rel=\"noopener\">https:\/\/mistral.ai\/fr\/technology\/#models<\/a><\/li>\n<\/ol>\n<p>First, I suck in excel so I&#8217;d rather go with python. Rapidly, I made a search on explanations about the ChatGPT and Mistral pricing because I am lazy. I found good ressources, especially this post: &#8220;Reduce Your OpenAI API Costs by 70%&#8221; at <a href=\"https:\/\/levelup.gitconnected.com\/reduce-your-openai-api-costs-by-70-a9f123ce55a6\" target=\"_blank\" rel=\"noopener\">https:\/\/levelup.gitconnected.com\/reduce-your-openai-api-costs-by-70-a9f123ce55a6<\/a><\/p>\n<p><b>This post introduces a fruitful correlation between cost efficiency and prompt design patterns!<\/b><\/p>\n<h2>Some tips on Cost efficiency &#038; Prompt Design Patterns<\/h2>\n<p><b>Here are notions quickly summarized that I kept from this post. The very first thing that you need to know is that, when you connect with an LLM via an API key, you are billed when sending content to the LLM (input) and when receiving content from the LLM (output). <\/b><\/p>\n<p><i>1. Number of tokens for a prompt<\/i><\/p>\n<p>For input, even though you&#8217;re sending a very short prompt, there  will be additional tokens sent within the prompt.<\/p>\n<blockquote><p>Notice that prompt_tokens, which refers to the input tokens, is 8. This is because every time you send text to the API, an additional 7 tokens are automatically added. <\/p><\/blockquote>\n<p>A good tool for ChatGPT, to count tokens number, it is to use this tool which calculates the tokens number from a text: <a href=\"https:\/\/www.tokencounter.io\/\" target=\"_blank\" rel=\"noopener\">https:\/\/www.tokencounter.io\/<\/a><\/p>\n<p><b>For LLM, the key element the Token so what you need to know is &#8220;what a token is?&#8221; which is the basic element that will be &#8220;input&#8221; and &#8220;output&#8221; by the LLM. <\/b><\/p>\n<p><b>For example, for an English text, 1 token corresponds to approximately 4 characters or 0.75 words. For reference, Shakespeare&#8217;s collected works are approximately 900,000 words or 1.2 million tokens. <\/b><\/p>\n<pre>\r\n# some examples\r\n\r\n1 token ~= 4 chars in English\r\n1 token ~= \u00be words\r\n100 tokens ~= 75 words\r\n\r\n1-2 sentence(s) ~= 30 tokens\r\n1 paragraph ~= 100 tokens\r\n1,500 words ~= 2048 tokens\r\n2,000 words ~= 2730 tokens\r\n<\/pre>\n<p><b>Simple Token definition<\/b><\/p>\n<blockquote><p>You can think of tokens as pieces of words used for natural language processing. For English text, 1 token is approximately 4 characters or 0.75 words. As a point of reference, the collected works of Shakespeare are about 900,000 words or 1.2M tokens. <\/p><\/blockquote>\n<p>Source: <a href=\"https:\/\/platform.openai.com\/tokenizer\" target=\"_blank\" rel=\"noopener\">https:\/\/platform.openai.com\/tokenizer<\/a><\/p>\n<p><i>2. Number of tokens for completion<\/i><br \/>\nYou will pay also what is produced by the LLM in the form of tokens.<\/p>\n<blockquote><p> The value is what we expected, representing the tokens in the response generated by the model.<\/p><\/blockquote>\n<p><b>See 001_reduce_api_costs.py, 002_reduce_api_costs.py, 003_reduce_api_costs.py at <a href=\"https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ai_pricing_llm\/reduce_api_costs\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ai_pricing_llm\/reduce_api_costs<\/a><\/b><\/p>\n<p><i>3. Clustering using OpenAI API<\/i><\/p>\n<p><b>Clustering, a great idea that must be explored if you intend to leverage on an LLM API KEY.<\/b><\/p>\n<p>Here a quick definition of the user need.<\/p>\n<blockquote><p> Imagine you have a huge list of news headlines and you want to cluster them. While using embeddings is one option, let\u2019s say you want to use OpenAI language models API, as it can capture meaning in a human-like way. Before we create the prompt template to minimize costs, let\u2019s look at what our news headlines list looks like. I&#8217;ve represented the news headlines in a shorter form, like s0, s1, s2, and so on. The reason for this is that when the language model clusters them, it can simply use these short abbreviations (e.g., s35 for the 35th news headline) instead of writing out the entire headline in each cluster. <\/p><\/blockquote>\n<p>Here is also a simple explanation of the expectation.<\/p>\n<blockquote><p> Next, I defined my prompt template. This template specifies the format of the answer I want the language model to provide, along with some additional information for clarity. The key here is that we\u2019re not asking the model to write out the full headlines, but rather to just use the short abbreviations. All we need to do is pass this prompt template to the function we created earlier and see how it performs in terms of pricing and response quality.<\/p><\/blockquote>\n<p><b>See 003_reduce_api_costs.py at <a href=\"https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ai_pricing_llm\/reduce_api_costs\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ai_pricing_llm\/reduce_api_costs<\/a><\/b><\/p>\n<p><i>4. SpellCheck using OpenAI API<\/i><br \/>\nPrompts enable you to do anything from summarize a text to code a script so why do not use LLM to correct spelling mistakes. The only drawback, the experience has been made in English only, I am not sure that the performances in correcting spelling mistakes are equivalent in any language.<\/p>\n<blockquote><p>Let\u2019s say you have a lengthy text document and you want to build a grammar correction tool as a small web app. While there are many NLP techniques available for this task, language models, particularly those from OpenAI, have been trained on vast amounts of data, making them a potentially better choice. Again, the key is to be strategic with our prompt template. We want the API response to highlight incorrect words and suggest their correct spellings, rather than providing the entire corrected text as output.<\/p><\/blockquote>\n<p><b>See 005_reduce_api_costs.py, 006_reduce_api_costs.py at <a href=\"https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ai_pricing_llm\/reduce_api_costs\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ai_pricing_llm\/reduce_api_costs<\/a><\/b><\/p>\n<h2>Exploring the pricing of the NVIDIA platform<\/h2>\n<p>There is also an uncomplicated way to explore different types of LLMs, a bit like huggingface.co, which is to rely on the NVIDIA platform which provides a turnkey package of LLMs and a handful of credits for start your tests. Once you have overcome the complexity of the site, you have access to code and a set of models: llama3-70b, phi-3-mini, codegemma-7b, mistral-large\u2026<\/p>\n<p><code><br \/>\nhttps:\/\/build.nvidia.com\/explore\/discover#llama3-70b<br \/>\nhttps:\/\/build.nvidia.com\/explore\/discover#phi-3-mini<br \/>\nhttps:\/\/build.nvidia.com\/explore\/discover#codegemma-7b<br \/>\nhttps:\/\/build.nvidia.com\/mistralai\/mistral-large<br \/>\n... etc<br \/>\n<\/code><\/p>\n<p><b>See files at <a href=\"https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ai_pricing_llm\/using_nvidia_api\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ai_pricing_llm\/using_nvidia_api<\/a><\/b><\/p>\n<h2>Exploring basiclingua-LLM-Based-NLP<\/h2>\n<p>The author of the post &#8220;Reduce Your OpenAI API Costs by 70%&#8221; have developed an NLP library that uses LLM APIs to perform various tasks. It includes over thirty features, many of which works with similar cost-optimization strategies as described in this post.  <\/p>\n<p><b>The code available on the GitHub repository possess numerous prompts resources that can provide great sample and models to learn prompting. <\/b><\/p>\n<p><b>See files at <a href=\"https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ai_pricing_llm\/using_basiclingua\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ai_pricing_llm\/using_basiclingua<\/a><\/b><\/p>\n<p><b>Tasks resolved by BasicLINGUA<\/b><br \/>\nEntity Extraction, Text Summarization, Text Classification, Text Sentiment Analysis, Text Coreference Resolution, Text Intent Recognition, Text OCR, Text Anomaly Detection, Text Sense Disambiguation, Text Spellcheck<\/p>\n<pre lang=\"python\">\r\n\r\n\r\n\r\n############## EXTRACT PATTERNS ##############\r\n\r\n\t\t# Generate the prompt template\r\n        prompt_template = f'''\r\n        Given the input text:\r\n        user input: {user_input}\r\n\r\n        extract following patterns from it: {patterns}\r\n\r\n        output must be a python dictionary with keys as patterns and values as list of extracted patterns\r\n        '''\r\n\r\n\r\n\r\n\r\n############## NER EXTRACTION ##############\r\n\r\n\t\t# check if parameters are of correct type\r\n        if not isinstance(user_input, str):\r\n            raise TypeError(\"user_input must be of type str\")\r\n        if not isinstance(ner_tags, str):\r\n            raise TypeError(\"ner_tags must be of type str\")\r\n\r\n        # check if parameters are not empty\r\n        if not user_input:\r\n            raise ValueError(\"user_input cannot be empty\")\r\n\r\n        # user ner tags\r\n        if ner_tags != \"\":\r\n            user_ner_tags = f'''NER TAGS: {ner_tags}'''\r\n        else:\r\n            user_ner_tags = f'''NER TAGS: FAC, CARDINAL, NUMBER, DEMONYM, QUANTITY, TITLE, PHONE_NUMBER, NATIONAL, JOB, PERSON, LOC, NORP, TIME, CITY, EMAIL, GPE, LANGUAGE, PRODUCT, ZIP_CODE, ADDRESS, MONEY, ORDINAL, DATE, EVENT, CRIMINAL_CHARGE, STATE_OR_PROVINCE, RELIGION, DURATION, URL, WORK_OF_ART, PERCENT, CAUSE_OF_DEATH, COUNTRY, ORG, LAW, NAME, COUNTRY, RELIGION, TIME'''\r\n\r\n        # Generate the prompt template\r\n        prompt_template = f'''Given the input text:\r\n        user input: {user_input}\r\n        \r\n        perform NER detection on it.\r\n        {user_ner_tags}\r\n        answer must be in the format\r\n        tag:value\r\n        '''\r\n\r\n<\/pre>\n<p>Source: <a href=\"https:\/\/github.com\/FareedKhan-dev\/basiclingua-LLM-Based-NLP\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/FareedKhan-dev\/basiclingua-LLM-Based-NLP<\/a><\/p>\n<h2>A quick schematic process of validation of each AI feature<\/h2>\n<p>As a reminder, here is a detailed process to validate an IA feature. The validation process will be the same for each use case.<\/p>\n<ul>\n<li>Phase_1: R&#038;D phase with POCs<\/li>\n<li>Phase_2: User feedback to gauge quality, artisanal validation, progress on the quality level. <\/li>\n<li>Phase_3: Pilot phase integration into a business tool such as Backoffice. This pilot phase makes it possible to extend the validation phase to a larger sample of content and uses. This integration will be done via Feature flipping (the AI feature is only available to a limited number of users). This makes it possible to test\/validate by having usage feedback on potential problems (performance, connectivity, refine usage based on production content, etc.). This is a Fine-tuning phase. <\/li>\n<li>Phase_4: Put into production, opening of the feature to all users in the business tool e.g. Backoffice. The feature nevertheless continues to evolve because of improvement of the existing model or by changing the model. <\/li>\n<\/ul>\n<p>As soon as the integration is done in a business tool, phase_3 must be carried out identically.<\/p>\n<p><H2>More infos<\/H2><\/p>\n<ul>\n<li>Reduce Your OpenAI API Costs by 70% | by Fareed Khan | Mar, 2024 | Level Up Coding<br \/><a href=\"https:\/\/levelup.gitconnected.com\/reduce-your-openai-api-costs-by-70-a9f123ce55a6\" target=\"_blank\" rel=\"noopener\">https:\/\/levelup.gitconnected.com\/reduce-your-openai-api-costs-by-70-a9f123ce55a6<\/a><\/li>\n<li>Pricing ChatGPT<br \/><a href=\"https:\/\/openai.com\/api\/pricing\" target=\"_blank\" rel=\"noopener\">https:\/\/openai.com\/api\/pricing<\/a><\/li>\n<li>Technologie | Mistral AI | Frontier AI in your hands<br \/><a href=\"https:\/\/mistral.ai\/fr\/technology\/#models\" target=\"_blank\" rel=\"noopener\">https:\/\/mistral.ai\/fr\/technology\/#models<\/a><\/li>\n<li>GitHub &#8211; FareedKhan-dev\/basiclingua-LLM-Based-NLP: LLM Based NLP Library.<br \/><a href=\"https:\/\/github.com\/FareedKhan-dev\/basiclingua-LLM-Based-NLP\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/FareedKhan-dev\/basiclingua-LLM-Based-NLP<\/a><\/li>\n<li>Long document content extraction | OpenAI Cookbook<br \/><a href=\"https:\/\/cookbook.openai.com\/examples\/entity_extraction_for_long_documents\" target=\"_blank\" rel=\"noopener\">https:\/\/cookbook.openai.com\/examples\/entity_extraction_for_long_documents<\/a><\/li>\n<li>Reduce Your OpenAI API Costs by 70% | by Fareed Khan | Mar, 2024 | Level Up Coding<br \/><a href=\"https:\/\/levelup.gitconnected.com\/reduce-your-openai-api-costs-by-70-a9f123ce55a6\" target=\"_blank\" rel=\"noopener\">https:\/\/levelup.gitconnected.com\/reduce-your-openai-api-costs-by-70-a9f123ce55a6<\/a><\/li>\n<li>GitHub &#8211; FareedKhan-dev\/basiclingua-LLM-Based-NLP: LLM Based NLP Library.<br \/><a href=\"https:\/\/github.com\/FareedKhan-dev\/basiclingua-LLM-Based-NLP\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/FareedKhan-dev\/basiclingua-LLM-Based-NLP<\/a><\/li>\n<li>Understanding OpenAI API Cost In-Depth Using a Real Example &#8211; WordBot<br \/><a href=\"https:\/\/blog.wordbot.io\/ai-artificial-intelligence\/understanding-gpt3-cost-in-depth-using-a-real-example\/\" target=\"_blank\" rel=\"noopener\">https:\/\/blog.wordbot.io\/ai-artificial-intelligence\/understanding-gpt3-cost-in-depth-using-a-real-example\/<\/a><\/li>\n<li>TokenCounter: tokenize and estimate your LLM costs<br \/><a href=\"https:\/\/www.tokencounter.io\/\" target=\"_blank\" rel=\"noopener\">https:\/\/www.tokencounter.io\/<\/a><\/li>\n<li>Create Your Azure Free Account Today | Microsoft Azure<br \/><a href=\"https:\/\/azure.microsoft.com\/en-us\/free\/ai-services\/\" target=\"_blank\" rel=\"noopener\">https:\/\/azure.microsoft.com\/en-us\/free\/ai-services\/<\/a><\/li>\n<li>\nMistral Large now available on Azure<br \/><a href=\"https:\/\/techcommunity.microsoft.com\/t5\/ai-machine-learning-blog\/mistral-large-mistral-ai-s-flagship-llm-debuts-on-azure-ai\/ba-p\/4066996\" target=\"_blank\" rel=\"noopener\">https:\/\/techcommunity.microsoft.com\/t5\/ai-machine-learning-blog\/mistral-large-mistral-ai-s-flagship-llm-debuts-on-azure-ai\/ba-p\/4066996<\/a><\/li>\n<li>GitHub &#8211; openai\/tiktoken: tiktoken is a fast BPE tokeniser for use with OpenAI&#8217;s models.<br \/><a href=\"https:\/\/github.com\/openai\/tiktoken\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/openai\/tiktoken<\/a><\/li>\n<li>GitHub &#8211; Promptly-Technologies-LLC\/llm_cost_estimation: A simple Python library for estimating what the cost of an API call will be<br \/><a href=\"https:\/\/github.com\/Promptly-Technologies-LLC\/llm_cost_estimation\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/Promptly-Technologies-LLC\/llm_cost_estimation<\/a><\/li>\n<li>GitHub &#8211; microsoft\/LLMLingua: To speed up LLMs&#8217; inference and enhance LLM&#8217;s perceive of key information, compress the prompt and KV-Cache, which achieves up to 20x compression with minimal performance loss.<br \/><a href=\"https:\/\/github.com\/microsoft\/LLMLingua\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/microsoft\/LLMLingua<\/a><\/li>\n<li>GitHub &#8211; magdalenakuhn17\/awesome-cheap-llms: Cost reduction tools and techniques for LLM based systems<br \/><a href=\"https:\/\/github.com\/magdalenakuhn17\/awesome-cheap-llms\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/magdalenakuhn17\/awesome-cheap-llms<\/a><\/li>\n<li>GitHub &#8211; AnthusAI\/LLM-Price-Comparison: A comparison of the price per million tokens and benchmark scores of various large language models.<br \/><a href=\"https:\/\/github.com\/AnthusAI\/LLM-Price-Comparison\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/AnthusAI\/LLM-Price-Comparison<\/a><\/li>\n<li>Build a Token Counter and Cost Estimator with Streamlit and OpenAI | by Tony Esposito | Medium<br \/><a href=\"https:\/\/medium.com\/@fbanespo\/build-a-token-counter-and-cost-estimator-with-streamlit-and-openai-2181e603f7cb\" target=\"_blank\" rel=\"noopener\">https:\/\/medium.com\/@fbanespo\/build-a-token-counter-and-cost-estimator-with-streamlit-and-openai-2181e603f7cb<\/a><\/li>\n<li>The Ultimate Pricing Cheat-Sheet for Large Language Models<br \/><a href=\"https:\/\/www.newtuple.com\/post\/the-ultimate-pricing-cheat-sheet-for-large-language-models\" target=\"_blank\" rel=\"noopener\">https:\/\/www.newtuple.com\/post\/the-ultimate-pricing-cheat-sheet-for-large-language-models<\/a><\/li>\n<li>Cost Analysis of deploying LLMs: A comparative Study between Cloud Managed, Self-Hosted and 3rd Party LLMs | by Hugo Debes | Artefact Engineering and Data Science | Medium<br \/><a href=\"https:\/\/medium.com\/artefact-engineering-and-data-science\/llms-deployment-a-practical-cost-analysis-e0c1b8eb08ca\" target=\"_blank\" rel=\"noopener\">https:\/\/medium.com\/artefact-engineering-and-data-science\/llms-deployment-a-practical-cost-analysis-e0c1b8eb08ca<\/a><\/li>\n<li>Your request has been blocked. This could be<br \/>\ndue to several reasons.<br \/><a href=\"https:\/\/www.microsoft.com\/en-us\/research\/group\/experimentation-platform-exp\/articles\/how-to-evaluate-llms-a-complete-metric-framework\/\" target=\"_blank\" rel=\"noopener\">https:\/\/www.microsoft.com\/en-us\/research\/group\/experimentation-platform-exp\/articles\/how-to-evaluate-llms-a-complete-metric-framework\/<\/a><\/li>\n<li>llm-cost-estimation \u2014 llm-cost-estimator latest documentation<br \/><a href=\"https:\/\/llm-cost-estimator.readthedocs.io\/en\/latest\/index.html\" target=\"_blank\" rel=\"noopener\">https:\/\/llm-cost-estimator.readthedocs.io\/en\/latest\/index.html<\/a><\/li>\n<li>GitHub &#8211; egordm\/RougLLy: Quick and Realistic Cost Estimation for LLMs.<br \/><a href=\"https:\/\/github.com\/egordm\/RougLLy\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/egordm\/RougLLy<\/a><\/li>\n<li>Paul Simmering \u2013 LLM Price Comparison<br \/><a href=\"https:\/\/simmering.dev\/blog\/llm-price-performance\/\" target=\"_blank\" rel=\"noopener\">https:\/\/simmering.dev\/blog\/llm-price-performance\/<\/a><\/li>\n<li>Understanding the cost of Large Language Models (LLMs)<br \/><a href=\"https:\/\/www.tensorops.ai\/post\/understanding-the-cost-of-large-language-models-llms\" target=\"_blank\" rel=\"noopener\">https:\/\/www.tensorops.ai\/post\/understanding-the-cost-of-large-language-models-llms<\/a><\/li>\n<li>Advanced Prompt Engineering &#8211; Practical Examples<br \/><a href=\"https:\/\/www.tensorops.ai\/post\/prompt-engineering-techniques-practical-guide\" target=\"_blank\" rel=\"noopener\">https:\/\/www.tensorops.ai\/post\/prompt-engineering-techniques-practical-guide<\/a><\/li>\n<li>GitHub &#8211; TensorOpsAI\/LLMstudio: Framework to bring LLM applications to production<br \/><a href=\"https:\/\/github.com\/TensorOpsAI\/LLMStudio\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/TensorOpsAI\/LLMStudio<\/a><\/li>\n<li>TokenCounter: tokenize and estimate your LLM costs<br \/><a href=\"https:\/\/www.tokencounter.io\/\" target=\"_blank\" rel=\"noopener\">https:\/\/www.tokencounter.io\/<\/a><\/li>\n<li>LLM Price Calculator<br \/><a href=\"https:\/\/www.llmcalc.com\/\" target=\"_blank\" rel=\"noopener\">https:\/\/www.llmcalc.com\/<\/a><\/li>\n<li>Compare LLM API Pricing Instantly &#8211; Get the Best Deals at LLM Price Check<br \/><a href=\"https:\/\/llmpricecheck.com\/\" target=\"_blank\" rel=\"noopener\">https:\/\/llmpricecheck.com\/<\/a><\/li>\n<li>LLM Pricing Calculator &#8211; LLM Price Check<br \/><a href=\"https:\/\/llmpricecheck.com\/calculator\" target=\"_blank\" rel=\"noopener\">https:\/\/llmpricecheck.com\/calculator<\/a><\/li>\n<li>llm_cost_estimation \u00b7 PyPI<br \/><a href=\"https:\/\/pypi.org\/project\/llm_cost_estimation\/\" target=\"_blank\" rel=\"noopener\">https:\/\/pypi.org\/project\/llm_cost_estimation\/<\/a><\/li>\n<li>LLM Pricing &#8211; Compare Large Language Model Costs and Pricing<br \/><a href=\"https:\/\/llm-price.com\/\" target=\"_blank\" rel=\"noopener\">https:\/\/llm-price.com\/<\/a><\/li>\n<li>GitHub &#8211; g-simmons\/llm-cost-estimator: A simple cost estimator for batch text generation with OpenAI LLMs<br \/><a href=\"https:\/\/github.com\/g-simmons\/llm-cost-estimator\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/g-simmons\/llm-cost-estimator<\/a><\/li>\n<li>GitHub &#8211; AgentOps-AI\/tokencost: Easy token price estimates for LLMs<br \/><a href=\"https:\/\/github.com\/AgentOps-AI\/tokencost\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/AgentOps-AI\/tokencost<\/a><\/li>\n<li>50+ Open-Source Options for Running LLMs Locally &#8211; Vince Lam<br \/><a href=\"https:\/\/vinlam.com\/posts\/local-llm-options\/\" target=\"_blank\" rel=\"noopener\">https:\/\/vinlam.com\/posts\/local-llm-options\/<\/a><\/li>\n<li>GitHub &#8211; VidhyaVarshanyJS\/EnsembleX: EnsembleX utilizes the Knapsack algorithm to optimize Large Language Model (LLM) ensembles for quality-cost trade-offs, offering tailored suggestions across various domains through a Streamlit dashboard visualization.<br \/><a href=\"https:\/\/github.com\/VidhyaVarshanyJS\/EnsembleX\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/VidhyaVarshanyJS\/EnsembleX<\/a><\/li>\n<li>Tokenizer<br \/><a href=\"https:\/\/platform.openai.com\/tokenizer\" target=\"_blank\" rel=\"noopener\">https:\/\/platform.openai.com\/tokenizer<\/a><\/li>\n<li>Log in with Atlassian account<br \/><a href=\"https:\/\/francemm.atlassian.net\/browse\/IA-98\" target=\"_blank\" rel=\"noopener\">https:\/\/francemm.atlassian.net\/browse\/IA-98<\/a><\/li>\n<li>Technologie | Mistral AI | Frontier AI in your hands<br \/><a href=\"https:\/\/mistral.ai\/fr\/technology\/\" target=\"_blank\" rel=\"noopener\">https:\/\/mistral.ai\/fr\/technology\/<\/a><\/li>\n<li>Usage tiers ChatGPT<br \/><a href=\"https:\/\/platform.openai.com\/docs\/guides\/rate-limits\/usage-tiers\" target=\"_blank\" rel=\"noopener\">https:\/\/platform.openai.com\/docs\/guides\/rate-limits\/usage-tiers<\/a><\/li>\n<li>Technologie | Mistral AI | Frontier AI in your hands<br \/><a href=\"https:\/\/mistral.ai\/fr\/technology\/\" target=\"_blank\" rel=\"noopener\">https:\/\/mistral.ai\/fr\/technology\/<\/a><\/li>\n<li>Pay As You Go\u2014Buy Directly | Microsoft Azure<br \/><a href=\"https:\/\/azure.microsoft.com\/en-us\/pricing\/purchase-options\/pay-as-you-go\" target=\"_blank\" rel=\"noopener\">https:\/\/azure.microsoft.com\/en-us\/pricing\/purchase-options\/pay-as-you-go<\/a><\/li>\n<li>\nMistral Large now available on Azure <br \/><a href=\"https:\/\/techcommunity.microsoft.com\/t5\/ai-machine-learning-blog\/mistral-large-mistral-ai-s-flagship-llm-debuts-on-azure-ai\/ba-p\/4066996\" target=\"_blank\" rel=\"noopener\">https:\/\/techcommunity.microsoft.com\/t5\/ai-machine-learning-blog\/mistral-large-mistral-ai-s-flagship-llm-debuts-on-azure-ai\/ba-p\/4066996<\/a><\/li>\n<li>Azure AI | Mistral AI Large Language Models<br \/><a href=\"https:\/\/docs.mistral.ai\/deployment\/cloud\/azure\/\" target=\"_blank\" rel=\"noopener\">https:\/\/docs.mistral.ai\/deployment\/cloud\/azure\/<\/a><\/li>\n<\/ul>\n",
            "protected": false
        },
        "excerpt": {
            "rendered": "<p>&#8220;After all, we are not communist&#8221; says Emilio &#8220;The Wolf&#8221; Barzini in the Godafather* and indeed despite the virtuous storytelling, IA is here to make&hellip; <\/p>\n<p class=\"text-center\"><a href=\"https:\/\/flaven.fr\/2024\/05\/unraveling-the-cost-of-ai-the-hidden-expenses-of-api-keys-and-pay-as-you-go-pricing-in-ai-based-products\/\" class=\"more-link\">Continue reading &rarr; <span class=\"screen-reader-text\">Unraveling the Cost of AI: The Hidden Expenses of API Keys and Pay-as-You-Go Pricing in AI-Based Products<\/span><\/a><\/p>\n",
            "protected": false
        },
        "author": 1
    },
    {
        "id": 12774,
        "link": "https:\/\/flaven.fr\/2024\/04\/transform-your-ideas-into-reality-develop-an-advanced-llm-ai-app-with-mistral-and-chatgpts-expert-guidance-and-comprehensive-prompts\/",
        "title": {
            "rendered": "Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT&#8217;s Expert Guidance and Comprehensive Prompts"
        },
        "content": {
            "rendered": "<p>What to do once you identify the possible usages offered by AI? As a Product Owner, the risk is sometimes to pay lip service once again by describing needs but never really satisfying them!<\/p>\n<p><b>For this post, you can find all files, mostly prompts, on my GitHub account. See <a href=\"https:\/\/github.com\/bflaven\/ia_usages_code_depot\/tree\/main\/prompts\/prompts_webapp_api_fmm_ia\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/bflaven\/ia_usages_code_depot\/tree\/main\/prompts\/prompts_webapp_api_fmm_ia<\/a><\/b><\/p>\n<p>Other elements e.g extract in French from the readme of the project. See <a href=\"https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ia_building_llm_api_web_apps_start_finish\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ia_building_llm_api_web_apps_start_finish<\/a><\/b><\/p>\n<p>There is a French expression that summarize this fate is &#8220;se payer de mots&#8221; that could be translated by &#8220;to indulge in words&#8221;. You just talk, you never act. That is probably the meaning behind this Laozi&#8217;s quote that shaped Chinese wisdom <\/p>\n<blockquote><p>He who knows does not speak; he who speaks does not know. Laozi<\/p><\/blockquote>\n<p><b>So, I decide to move my a&#8230; then how to proceed?<\/b><\/p>\n<ul>\n<li>First, what is the better way than using AI to understand and make AI<\/li>\n<li>Second, the real added value resides in the prompts.<\/li>\n<\/ul>\n<p><b>For the moment, I decide not to release the code as I do not know the status of it regarding my professional situation but anyway with the help of the prompts it is like having an open book. So, You will find in the repository the list of 50 prompts that it took me to code a \u201cWebapp + API + LLM\u201d device from scratch.<\/b><\/p>\n<p><b>The Advanced LLM AI App relies on these elements:  Mistral is used as LLM, LangChain and Ollama as framework to query the LLM, FastAPI as framework to create the API and Streamlit as framework to create the web application.<\/b><\/p>\n<p><b>The challenge was being able to query Mistral as a LMM in a secure, confidential and for free while waiting to implement or not a paid API key for Mistral or ChatGPT.<\/b><\/p>\n<p>Again, some chineese wisdom, like Confucius said: <\/p>\n<blockquote><p>Give a man a fish and you feed him for a day, teach a man to fish and you feed him for a lifetime. Confucius<\/p><\/blockquote>\n<p>Instead of give a fish (coding), I teach you how to fish (prompting) \ud83d\ude42<\/p>\n<p>For more security concern, I don&#8217;t give the code as I risk putting myself at odds with my employer. On the other hand, I constantly need to refer to this knowledge base so what&#8217;s better than keeping the prompts and share it with myself and the rest of the world.<\/p>\n<p><b>At the end this post, I gave some screens captures from the final result.<\/b><\/p>\n<h2>Workplan<\/h2>\n<p>So, humbly and within my means, I therefore allowed myself to build a system to tackle the subject of AI in order to demystify its uses and its technicality.<\/p>\n<p>As demonstrated by the previous posts, you must already be able to simply state the objective pursued based on what you already know and what you are trying to do.<\/p>\n<p><b>Objective: The idea is to facilitate the AI&#8217;s exploration uses via user interfaces in order to obtain user feedback on the level of quality and acceptance of this or that AI functionality. : transcription, entity extraction, translation, summary&#8230;<\/b><\/p>\n<p>It requires creating interfaces that the user can grab as quickly as possible. It means removing all obstacles upstream, in order to connect these screens to artificial intelligence as quickly as possible.<\/p>\n<p>After some research, the idea that emerged was to set up, as quickly as possible, a complete system including the following building blocks: <b>LLM + API + WEBAPP<\/b>.<\/p>\n<p><b>This is the meaning of this graph below and which I introduce into the equation in point 1.<\/b><\/p>\n<p><img fetchpriority=\"high\" decoding=\"async\" width=\"800\" height=\"421\" src=\"https:\/\/flaven.fr\/wp-content\/uploads\/2024\/04\/workflow_webapp_api_llm_4_small.png\" alt=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\" title=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\"><\/p>\n<p>What&#8217;s amazing is that with the sole help of AI, designing, coding&#8230; so prototyping everything took about an intense week but only one week where it would have probably taken 6 months or even more.<\/p>\n<h2>1. The basic architecture<\/h2>\n<p>Well, the quickest and easiest way to apprehend IA.<\/p>\n<table>\n<thead>\n<tr>\n<th>Element<\/th>\n<th>Framework<\/th>\n<th>Functional Description<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>LLM<\/td>\n<td>Ollama + Mistral<\/td>\n<td>Leverages Ollama and Mistral for its functionality.<\/td>\n<\/tr>\n<tr>\n<td>API<\/td>\n<td>FastAPI<\/td>\n<td>The API is built using FastAPI and delivers various AI features such as summary generation with Bart, entity recognition with Spacy, transcription with Whisper, translation with NLLB, etc.<\/td>\n<\/tr>\n<tr>\n<td>WEBAPP<\/td>\n<td>Streamlit<\/td>\n<td>The WEBAPP is built using Streamlit and provides a human interface for accessing the endpoints of the API.<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<h2>2. And then? Introducing the usages<\/h2>\n<p>What functionalities should be included in this architecture and how to possibly go beyond basic uses and of course always rely on the fundamentals according to the DRY principle<\/p>\n<p><b>I ask ChatGPT and it gave me a quick roadmap. ChatGPT gave me a quick reminder on the best pratices to stick to avoid pitfalls, you can check below the regular stuff to do!<\/b><\/p>\n<p>In this architecture, the functionalities to consider can revolve around enhancing user experience, optimizing performance, extending data analysis and processing capabilities, as well as ensuring security. Here are some suggestions for each element of the architecture and how to go beyond basic usage while adhering to the DRY (Don&#8217;t Repeat Yourself) principle:<\/p>\n<h3>LLM:<\/h3>\n<ul>\n<li><b>Improvement of accuracy and reliability:<\/b> Integrate advanced machine learning techniques to enhance prediction quality.<\/li>\n<li><b>Customization:<\/b> Allow model customization to adapt to specific user needs.<\/li>\n<li><b>Interoperability:<\/b> Ensure seamless integration with other systems and external services.<\/li>\n<\/ul>\n<h3>API:<\/h3>\n<ul>\n<li><b>Scalability:<\/b> Design the API to effectively handle growing workloads.<\/li>\n<li><b>Comprehensive documentation:<\/b> Provide detailed API documentation to facilitate its use by third-party developers.<\/li>\n<li><b>Versioning:<\/b> Implement an API versioning system to allow evolution while maintaining backward compatibility.<\/li>\n<\/ul>\n<h3>WEBAPP:<\/h3>\n<ul>\n<li><b>User-friendly interface:<\/b> Design an intuitive and aesthetically pleasing user interface to enhance user experience.<\/li>\n<li><b>Performance optimization:<\/b> Optimize queries and loading times to ensure maximum responsiveness of the application.<\/li>\n<li><b>Real-time analysis:<\/b> Integrate real-time analysis features to enable users to visualize and understand data more quickly.<\/li>\n<\/ul>\n<h3>Going beyond basic usage while adhering to the DRY principle:<\/h3>\n<ul>\n<li><b>Modularity:<\/b> Design each element of the architecture in a modular way to promote code reuse and easy maintenance.<\/li>\n<li><b>Use of microservices:<\/b> Decompose functionalities into independent microservices to enable scalable development and efficient scaling.<\/li>\n<li><b>Automation:<\/b> Implement continuous integration and continuous deployment pipelines to automate development, testing, and deployment processes.<\/li>\n<li><b>Monitoring and logging:<\/b> Integrate monitoring and logging tools to track system performance, detect errors, and proactively improve code quality.<\/li>\n<\/ul>\n<p>By following these principles and integrating these functionalities, the architecture can be extended beyond basic usage while remaining compliant with the DRY principle, enabling the development of a robust, scalable, and easily maintainable system.<\/p>\n<p><b>So with these principles, I stuffed my architecture with my use cases which mechanically drew a roadmap.<\/b><\/p>\n<ul>\n<li>POC_1: A simple way to explore and interact with IA features through an API (Fastapi) connected to a WEBAPP (Streamlit).<\/li>\n<li>POC_2:  Some explorations on Chatbot Building with 2 main objectives : 1. Ask a local LMM (Mistral) via a ChatBot, therefore free and confidentially via Ollama. Of course, the system must be transposed to a paid model (ChatGPT, Mistral) and in the cloud (Azure); 2. Explore the notion of RAG (Retrieval-Augmented Generation). Functionally, this means building a knowledge base from heterogeneous content (.txt, .doc, docx, .pdf&#8230; etc.) then relying on a LLM like Mistral in order to query this knowledge base through a WEBAPP (Streamlit) that provided a ChatBot.\n<\/li>\n<li>POC_3: Turninng all these POC into a reliable docker-compose that support a backend (API made with FastAPI) and frontend (a WEBAPP made with Streamlit)\n<\/ul>\n<p>For me, the highest step was obviously the addition of an LMM in this device in order to be able to prompt in a confidential and secure manner. In case of failure, I will have opted for Buy instead of Build.<\/p>\n<h2>2. The RAG pack (POC_2)<\/h2>\n<p>Just a few words on the POC_2, on the RAG. I had never heard of this thing but incidentally, once the basic architecture is set up, you can easily launch grapples towards other uses such as Rag for example.<\/p>\n<p><b>For those, who do not know what is a RAG?<\/b><br \/>\nHere is the most straightforward explanations that I found on the web and that mostly focus on user benefices.<\/p>\n<p>The source is this post<br \/>\n&#8220;Retrieval-Augmented Generation (RAG): From Theory to LangChain Implementation&#8221;: <a href=\"https:\/\/towardsdatascience.com\/retrieval-augmented-generation-rag-from-theory-to-langchain-implementation-4e9bd5f6a4f2\" target=\"_blank\" rel=\"noopener\">https:\/\/towardsdatascience.com\/retrieval-augmented-generation-rag-from-theory-to-langchain-implementation-4e9bd5f6a4f2<\/a><\/p>\n<blockquote><p>Retrieval-Augmented Generation (RAG) is the concept to provide LLMs with additional information from an external knowledge source. This allows them to generate more accurate and contextual answers while reducing hallucinations.<\/p><\/blockquote>\n<blockquote><p>In simple terms, RAG is to LLMs what an open-book exam is to humans. In an open-book exam, students are allowed to bring reference materials, such as textbooks or notes, which they can use to look up relevant information to answer a question. The idea behind an open-book exam is that the test focuses on the students\u2019 reasoning skills rather than their ability to memorize specific information.<\/p><\/blockquote>\n<p><b>On the RAG, you can find various prompts and code at <a href=\"https:\/\/github.com\/bflaven\/ia_usages_code_depot\/tree\/main\/prompts\/prompts_serie_conversational_chat\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/bflaven\/ia_usages_code_depot\/tree\/main\/prompts\/prompts_serie_conversational_chat<\/a><\/b><\/p>\n<h2>3. A small extra : using FLOWISEAI<\/h2>\n<p>During, this exploration, I have discovered FLOWISEAI and great videos from @leonvanzyl.<br \/>\nFLOWISEAI is a very intuitive software that should be used for many uses such as RAG for instance. It is UX-oriented and user-centric to enable anyone to get to crip with IA concepts such as Prompt, Rag, Chatbot&#8230; FLOWISEAI is as great as Streamlit.<\/p>\n<ul>\n<li><a href=\"https:\/\/www.youtube.com\/@leonvanzyl\/videos\" target=\"_blank\" rel=\"noopener\">https:\/\/www.youtube.com\/@leonvanzyl\/videos<\/a><\/li>\n<li><a href=\"https:\/\/www.restack.io\/store\/flowise\" target=\"_blank\" rel=\"noopener\">https:\/\/www.restack.io\/store\/flowise<\/a><\/li>\n<li><a href=\"https:\/\/flowiseai.com\/\" target=\"_blank\" rel=\"noopener\">https:\/\/flowiseai.com\/<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/FlowiseAI\/Flowise\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/FlowiseAI\/Flowise<\/a><\/li>\n<\/ul>\n<p><b>HOW TO INSTALL FLOWISEAI<\/b><\/p>\n<pre>\r\n# go to dir\r\ncd \/Users\/brunoflaven\/Documents\/01_work\/blog_articles\/ia_using_flowiseai\/\r\n\r\n# create dir\r\nmkdir flowiseai\r\n\r\n# go to the dir flowiseai\r\ncd flowiseai\r\n\r\n# install flowise\r\nnpm install flowise\r\n\r\n# install flowise globally\r\nnpm install -g flowise\r\nnpm uninstall -g flowise\r\n\r\n# start flowise\r\nnpx flowise start\r\n\r\n# check the site\r\nhttp:\/\/localhost:3000\/\r\n\r\n# Other documentation\r\n# https:\/\/www.langchain.com\/\r\n<\/pre>\n<h2>4. Screens captures for &#8220;Webapp + API + LLM&#8221;<\/h2>\n<p><b>CONSOLE_SCREEN_1 for the API (fastapi)<\/b><br \/>\n<img fetchpriority=\"high\" decoding=\"async\" width=\"800\" height=\"421\" src=\"https:\/\/flaven.fr\/wp-content\/uploads\/2024\/04\/console_1_fastapi.jpg\" alt=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\" title=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\"><\/p>\n<p><b>CONSOLE_SCREEN_2 for the WEBAPP (streamlit)<\/b><br \/>\n<img fetchpriority=\"high\" decoding=\"async\" width=\"800\" height=\"421\" src=\"https:\/\/flaven.fr\/wp-content\/uploads\/2024\/04\/console_2_streamlit.jpg\" alt=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\" title=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\"><\/p>\n<p><b>CONSOLE_SCREEN_3 for the LLM (ollama + Mistral)<\/b><br \/>\n<img fetchpriority=\"high\" decoding=\"async\" width=\"800\" height=\"421\" src=\"https:\/\/flaven.fr\/wp-content\/uploads\/2024\/04\/console_3_ollama.jpg\" alt=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\" title=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\"><\/p>\n<p><b>Easy to create documentation (swagger) for this API (fastapi) for various endpoints IA<\/b><br \/>\n<img fetchpriority=\"high\" decoding=\"async\" width=\"800\" height=\"421\" src=\"https:\/\/flaven.fr\/wp-content\/uploads\/2024\/04\/ia_building_llm_api_web_apps_start_finish_1.jpg\" alt=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\" title=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\"><\/p>\n<p><b>Transcription using Whisper from OpenAI<\/b><br \/>\n<img fetchpriority=\"high\" decoding=\"async\" width=\"800\" height=\"421\" src=\"https:\/\/flaven.fr\/wp-content\/uploads\/2024\/04\/ia_building_llm_api_web_apps_start_finish_2.jpg\" alt=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\" title=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\"><\/p>\n<p><b>Spelling correction of text in FR. It&#8217;s not AI, it&#8217;s just integration. 12 possible languages See Online spelling, style and grammar checker &#8211; LanguageTool<\/b><br \/>\n<img fetchpriority=\"high\" decoding=\"async\" width=\"800\" height=\"421\" src=\"https:\/\/flaven.fr\/wp-content\/uploads\/2024\/04\/ia_building_llm_api_web_apps_start_finish_3.jpg\" alt=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\" title=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\"><\/p>\n<p><b>Extraction of entities from a text in English with Spacy. There are 18 types of extracted features.<\/b><br \/>\n<img fetchpriority=\"high\" decoding=\"async\" width=\"800\" height=\"421\" src=\"https:\/\/flaven.fr\/wp-content\/uploads\/2024\/04\/ia_building_llm_api_web_apps_start_finish_4.jpg\" alt=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\" title=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\"><\/p>\n<p><b>Extraction of entities from a text in English with Spacy. There are 18 types of extracted features.<\/b><br \/>\n<img fetchpriority=\"high\" decoding=\"async\" width=\"800\" height=\"421\" src=\"https:\/\/flaven.fr\/wp-content\/uploads\/2024\/04\/ia_building_llm_api_web_apps_start_finish_5.jpg\" alt=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\" title=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\"><\/p>\n<p><b>Social and SEO: Repackaging of content, with prompts, in a specific format for Social Networks: Based on a text, generation of a 140-character \u201cSMO friendly\u201d tweet with a proposal of 5 hashtags from the text. Functionality available via an LMM (Mistral). or Based on a text, generation of three editorial proposals for \u201cSEO friendly\u201d titles with a proposal of 5 keywords from the text. Functionality available via an LMM (Mistral)<\/b><br \/>\n<img fetchpriority=\"high\" decoding=\"async\" width=\"800\" height=\"421\" src=\"https:\/\/flaven.fr\/wp-content\/uploads\/2024\/04\/ia_building_llm_api_web_apps_start_finish_6.jpg\" alt=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\" title=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\"><\/p>\n<p><b>Social and SEO: Repackaging of content, with prompts, in a specific format for Social Networks: Based on a text, generation of a 140-character \u201cSMO friendly\u201d tweet with a proposal of 5 hashtags from the text. Functionality available via an LMM (Mistral). or Based on a text, generation of three editorial proposals for \u201cSEO friendly\u201d titles with a proposal of 5 keywords from the text. Functionality available via an LMM (Mistral)<\/b><br \/>\n<img fetchpriority=\"high\" decoding=\"async\" width=\"800\" height=\"421\" src=\"https:\/\/flaven.fr\/wp-content\/uploads\/2024\/04\/ia_building_llm_api_web_apps_start_finish_7.jpg\" alt=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\" title=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\"><\/p>\n<p><b>Social and SEO: Ditto! The result is exported with the help of Panda in CSV format<\/b><br \/>\n<img fetchpriority=\"high\" decoding=\"async\" width=\"800\" height=\"421\" src=\"https:\/\/flaven.fr\/wp-content\/uploads\/2024\/04\/ia_building_llm_api_web_apps_start_finish_8.jpg\" alt=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\" title=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\"><\/p>\n<p><b>Summary: Repackaging of content, with prompts, in &#8220;Summary&#8221; format: creation of a long summary from a text in FR and EN with selection of 5 significant keywords from the text with for a LLM (ollama + Mistral). There is also 3 types of summary endpoints one using Bart, another using BART model with ktrain.<\/b><br \/>\n<img fetchpriority=\"high\" decoding=\"async\" width=\"800\" height=\"421\" src=\"https:\/\/flaven.fr\/wp-content\/uploads\/2024\/04\/ia_building_llm_api_web_apps_start_finish_9.jpg\" alt=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\" title=\"Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT's Expert Guidance and Comprehensive Prompts\"><\/p>\n<p><b>List of the endpoints available through the API (fastapi) then you just must make the interface to make it work in the WEBAPP (Streamlit) and for sure provide for each point the IA feature.<\/b><\/p>\n<pre>\r\n# tags_metadata\r\ntags_metadata = [\r\n    {\r\n        'name': 'healthcheck',\r\n        'description': 'TRUE. It basically sends a GET request to the route & hopes to get a \"200\"'\r\n    },\r\n    {\r\n        'name': 'write',\r\n        'description': 'TRUE. Write to the DB. Post inside table \"source_content_posts\"'\r\n    },\r\n    {\r\n        'name': 'read',\r\n        'description': 'TRUE. Get all content from the DB. Read from table \"source_content_posts\"'\r\n    },\r\n    {\r\n        'name': 'spelling',\r\n        'description': 'TRUE. Able to launch a spell checking on text. Read from field \"text\" from table \"source_content_posts\"'\r\n    },\r\n    {\r\n        'name': 'entities',\r\n        'description': 'TRUE. Extract a entities from a text only in ENGLISH with Spacy (NER).'\r\n    },\r\n    {\r\n        'name': 'translate',\r\n        'description': 'Text to present translation with nllb-200-distilled-600M'\r\n    },\r\n    {\r\n        'name': 'translate_languages',\r\n        'description': 'Text to present languages for nllb-200-distilled-600M'\r\n    },\r\n    {\r\n        'name': 'summary_bart',\r\n        'description': 'TRUE. This endpoint generates a summary of the given text input using BART model.'\r\n    },\r\n    {\r\n        'name': 'summary_bart_conditional_generation',\r\n        'description': 'TRUE. This endpoint generates a summary of the given text input using BART model.'\r\n    },\r\n    {\r\n        'name': 'summary_ktrain_transformer_summarizer',\r\n        'description': 'TRUE. This endpoint accepts a text document and returns a summary generated by the BART model using ktrain.'\r\n    },\r\n    {\r\n        'name': 'llm_generate',\r\n        'description': 'TRUE. This endpoint accepts a text document and returns different elements depending prompt selected: English SEO-friendly title with keywords, French SEO-friendly title with keywords, a twitter SMO-friendly with hastags. It leverages on Mistral.'\r\n    },\r\n    {\r\n        'name': 'llm_operate',\r\n        'description': 'TRUE. This endpoint accepts a text document and proceeds to different operations such as summary of the text content. It leverages on Mistral.'\r\n    },\r\n    {\r\n        'name': 'audio',\r\n        'description': 'This is the audio transcription with Whisper. It works in 70 languages.'\r\n    },\r\n    {\r\n        'name': 'audio_express',\r\n        'description': 'This is the audio transcription with faster_whisper and WhisperModel. It works in 70 languages.'\r\n    },\r\n    {\r\n        'name': 'video',\r\n        'description': 'This is the video transcription with Whisper. It works in 70 languages.'\r\n\r\n    },\r\n    {\r\n        'name': 'video_express',\r\n        'description': 'This is the audio transcription with faster_whisper and WhisperModel. It works in 70 languages.'\r\n    },\r\n]\r\n<\/pre>\n<p><H2>More infos<\/H2><\/p>\n<ul>\n<li>Building LLM-Powered Web Apps with Client-Side Technology \u00b7 Ollama Blog<br \/><a href=\"https:\/\/ollama.com\/blog\/building-llm-powered-web-apps\" target=\"_blank\" rel=\"noopener\">https:\/\/ollama.com\/blog\/building-llm-powered-web-apps<\/a><\/li>\n<li>Community | Run Large Language Models with Ollama and AWS Lightsail for Research<br \/><a href=\"https:\/\/community.aws\/posts\/run-large-language-models-with-ollama-and-lightsail-for-research\" target=\"_blank\" rel=\"noopener\">https:\/\/community.aws\/posts\/run-large-language-models-with-ollama-and-lightsail-for-research<\/a><\/li>\n<li>Naomi Oreskes, historienne des sciences\u00a0: \u00ab\u00a0Nous mettons en \u0153uvre aux Etats-Unis des id\u00e9es politiques qui ne fonctionnent pas. Nous payons le prix fort du libre march\u00e9\u00a0\u00bb<br \/><a href=\"https:\/\/www.lemonde.fr\/idees\/article\/2024\/03\/03\/naomi-oreskes-nous-devons-etre-attentifs-a-la-maniere-dont-la-vie-intellectuelle-peut-etre-faconnee-par-les-interets-des-entreprises_6219816_3232.html\" target=\"_blank\" rel=\"noopener\">https:\/\/www.lemonde.fr\/idees\/article\/2024\/03\/03\/naomi-oreskes-nous-devons-etre-attentifs-a-la-maniere-dont-la-vie-intellectuelle-peut-etre-faconnee-par-les-interets-des-entreprises_6219816_3232.html<\/a><\/li>\n<li>cairn.info<br \/><a href=\"https:\/\/www.cairn.info\/revue-pouvoirs-2019-3-page-119.htm\" target=\"_blank\" rel=\"noopener\">https:\/\/www.cairn.info\/revue-pouvoirs-2019-3-page-119.htm<\/a><\/li>\n<li>Build your own RAG and run it locally: Langchain + Ollama + Streamlit<br \/><a href=\"https:\/\/blog.duy-huynh.com\/build-your-own-rag-and-run-them-locally\/\" target=\"_blank\" rel=\"noopener\">https:\/\/blog.duy-huynh.com\/build-your-own-rag-and-run-them-locally\/<\/a><\/li>\n<li>GitHub &#8211; jacttp\/simpleRAG: Mistral RAG  for chating with pdfs, UI with streamlit<br \/><a href=\"https:\/\/github.com\/jacttp\/simpleRAG\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/jacttp\/simpleRAG<\/a><\/li>\n<li>GitHub &#8211; vndee\/local-rag-example: Build your own ChatPDF and run them locally<br \/><a href=\"https:\/\/github.com\/vndee\/local-rag-example.git\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/vndee\/local-rag-example.git<\/a><\/li>\n<li>Building a Local PDF Chat Application with Mistral 7B LLM, Langchain, Ollama, and Streamlit | by Harjot | Medium<br \/><a href=\"https:\/\/medium.com\/@harjot802\/building-a-local-pdf-chat-application-with-mistral-7b-llm-langchain-ollama-and-streamlit-67b314fbab57\" target=\"_blank\" rel=\"noopener\">https:\/\/medium.com\/@harjot802\/building-a-local-pdf-chat-application-with-mistral-7b-llm-langchain-ollama-and-streamlit-67b314fbab57<\/a><\/li>\n<li>GitHub &#8211; SonicWarrior1\/pdfchat: Local PDF Chat Application with Mistral 7B LLM, Langchain, Ollama, and Streamlit<br \/><a href=\"https:\/\/github.com\/SonicWarrior1\/pdfchat\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/SonicWarrior1\/pdfchat<\/a><\/li>\n<li>GitHub &#8211; nilsjennissen\/mistral: Mistral 7B Streamlit Application<br \/><a href=\"https:\/\/github.com\/nilsjennissen\/mistral\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/nilsjennissen\/mistral<\/a><\/li>\n<li>GitHub &#8211; alros\/rag-python at a325cc2a31a6700f12a48c20ef4e546c7fd58673<br \/><a href=\"https:\/\/github.com\/alros\/rag-python\/tree\/a325cc2a31a6700f12a48c20ef4e546c7fd58673\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/alros\/rag-python\/tree\/a325cc2a31a6700f12a48c20ef4e546c7fd58673<\/a><\/li>\n<li>Your own ChatGPT for $0.04\/hr &#8211; With Ollama, ChatUI &#038; Salad<br \/><a href=\"https:\/\/blog.salad.com\/ollama-deploy-chatgpt\/\" target=\"_blank\" rel=\"noopener\">https:\/\/blog.salad.com\/ollama-deploy-chatgpt\/<\/a><\/li>\n<li>Mistral 7B RAG Tutorial: Build RAG Application Easily &#8211; YouTube<br \/><a href=\"https:\/\/www.youtube.com\/watch?v=3dqH6HI5rrU\" target=\"_blank\" rel=\"noopener\">https:\/\/www.youtube.com\/watch?v=3dqH6HI5rrU<\/a><\/li>\n<li>GitHub &#8211; Yashmori09\/Website-Chatbot-Mistral7b-RAG-App<br \/><a href=\"https:\/\/github.com\/Yashmori09\/Website-Chatbot-Mistral7b-RAG-App\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/Yashmori09\/Website-Chatbot-Mistral7b-RAG-App<\/a><\/li>\n<li>Using Retrieval Augmented Generation with a Large Language Model AI Chatbot &#8211; YouTube<br \/><a href=\"https:\/\/www.youtube.com\/watch?v=XctooiH0moI\" target=\"_blank\" rel=\"noopener\">https:\/\/www.youtube.com\/watch?v=XctooiH0moI<\/a><\/li>\n<li>Running Mistral AI on your machine with Ollama &#8211; YouTube<br \/><a href=\"https:\/\/www.youtube.com\/watch?v=NFgEgqua-fg\" target=\"_blank\" rel=\"noopener\">https:\/\/www.youtube.com\/watch?v=NFgEgqua-fg<\/a><\/li>\n<li>GitHub &#8211; kesamet\/ai-assistant at 34b0af2eb5d8266625a5ff9c28ec8c9c7a4c59a6<br \/><a href=\"https:\/\/github.com\/kesamet\/ai-assistant\/tree\/34b0af2eb5d8266625a5ff9c28ec8c9c7a4c59a6\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/kesamet\/ai-assistant\/tree\/34b0af2eb5d8266625a5ff9c28ec8c9c7a4c59a6<\/a><\/li>\n<li>GitHub &#8211; yassineselmi\/langchain-workshop at 1f39fc156d48f9143409fd7924bddff1e776546c<br \/><a href=\"https:\/\/github.com\/yassineselmi\/langchain-workshop\/tree\/1f39fc156d48f9143409fd7924bddff1e776546c\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/yassineselmi\/langchain-workshop\/tree\/1f39fc156d48f9143409fd7924bddff1e776546c<\/a><\/li>\n<li>GitHub &#8211; mmahmad\/localmodel-ui<br \/><a href=\"https:\/\/github.com\/mmahmad\/localmodel-ui\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/mmahmad\/localmodel-ui<\/a><\/li>\n<li>Build a chatbot with custom data sources, powered by LlamaIndex<br \/><a href=\"https:\/\/blog.streamlit.io\/build-a-chatbot-with-custom-data-sources-powered-by-llamaindex\/\" target=\"_blank\" rel=\"noopener\">https:\/\/blog.streamlit.io\/build-a-chatbot-with-custom-data-sources-powered-by-llamaindex\/<\/a><\/li>\n<li>llamaindex-chat-with-streamlit-docs\/streamlit_app.py at main \u00b7 carolinedlu\/llamaindex-chat-with-streamlit-docs \u00b7 GitHub<br \/><a href=\"https:\/\/github.com\/carolinedlu\/llamaindex-chat-with-streamlit-docs\/blob\/main\/streamlit_app.py\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/carolinedlu\/llamaindex-chat-with-streamlit-docs\/blob\/main\/streamlit_app.py<\/a><\/li>\n<li>GitHub &#8211; nilsjennissen\/law-search-llm: A local Large Language Model Application for legal document seach<br \/><a href=\"https:\/\/github.com\/nilsjennissen\/law-search-llm\/tree\/main\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/nilsjennissen\/law-search-llm\/tree\/main<\/a><\/li>\n<li>fullstack-gpt\/pages at caedeff863c57ba38f37d51a0415e471a7422250 \u00b7 Jinwook-Song\/fullstack-gpt \u00b7 GitHub<br \/><a href=\"https:\/\/github.com\/Jinwook-Song\/fullstack-gpt\/tree\/caedeff863c57ba38f37d51a0415e471a7422250\/pages\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/Jinwook-Song\/fullstack-gpt\/tree\/caedeff863c57ba38f37d51a0415e471a7422250\/pages<\/a><\/li>\n<li>GitHub &#8211; tGhattas\/LLM-chat at 6d89be198a535878c3f817e02f6b399f43ab9497<br \/><a href=\"https:\/\/github.com\/tGhattas\/LLM-chat\/tree\/6d89be198a535878c3f817e02f6b399f43ab9497\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/tGhattas\/LLM-chat\/tree\/6d89be198a535878c3f817e02f6b399f43ab9497<\/a><\/li>\n<li>Google Colab<br \/><a href=\"https:\/\/colab.research.google.com\/github\/mistralai\/cookbook\/blob\/main\/basic_RAG.ipynb\" target=\"_blank\" rel=\"noopener\">https:\/\/colab.research.google.com\/github\/mistralai\/cookbook\/blob\/main\/basic_RAG.ipynb<\/a><\/li>\n<li>cookbook\/langgraph_crag_mistral.ipynb at main \u00b7 mistralai\/cookbook \u00b7 GitHub<br \/><a href=\"https:\/\/github.com\/mistralai\/cookbook\/blob\/main\/langgraph_crag_mistral.ipynb\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/mistralai\/cookbook\/blob\/main\/langgraph_crag_mistral.ipynb<\/a><\/li>\n<li>GitHub &#8211; mistralai\/cookbook<br \/><a href=\"https:\/\/github.com\/mistralai\/cookbook\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/mistralai\/cookbook<\/a><\/li>\n<li>GitHub &#8211; ohdoking\/ollama-with-rag: Ollama with RAG and Chainlit is a chatbot project leveraging Ollama, RAG, and Chainlit. It uses Chromadb for vector storage, gpt4all for text embeddings, and includes a fine-tuning and evaluation module for language models.<br \/><a href=\"https:\/\/github.com\/ohdoking\/ollama-with-rag\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/ohdoking\/ollama-with-rag<\/a><\/li>\n<li>A Step-by-Step Guide to PDF Chatbots with Langchain and Ollama &#8211; Analytics Vidhya<br \/><a href=\"https:\/\/www.analyticsvidhya.com\/blog\/2023\/10\/a-step-by-step-guide-to-pdf-chatbots-with-langchain-and-ollama\/\" target=\"_blank\" rel=\"noopener\">https:\/\/www.analyticsvidhya.com\/blog\/2023\/10\/a-step-by-step-guide-to-pdf-chatbots-with-langchain-and-ollama\/<\/a><\/li>\n<li>Flowise AI (2024) Tutorial &#8211; YouTube<br \/><a href=\"https:\/\/www.youtube.com\/playlist?list=PL4HikwTaYE0H7wBxhvQqxYcKOkZ4O3zXh\" target=\"_blank\" rel=\"noopener\">https:\/\/www.youtube.com\/playlist?list=PL4HikwTaYE0H7wBxhvQqxYcKOkZ4O3zXh<\/a><\/li>\n<li>LangChain<br \/><a href=\"https:\/\/www.langchain.com\/\" target=\"_blank\" rel=\"noopener\">https:\/\/www.langchain.com\/<\/a><\/li>\n<li>LangChain Python Tutorial &#8211; YouTube<br \/><a href=\"https:\/\/www.youtube.com\/playlist?list=PL4HikwTaYE0GEs7lvlYJQcvKhq0QZGRVn\" target=\"_blank\" rel=\"noopener\">https:\/\/www.youtube.com\/playlist?list=PL4HikwTaYE0GEs7lvlYJQcvKhq0QZGRVn<\/a><\/li>\n<li>Using LangSmith to test LLMs and AI applications &#8211; LogRocket Blog<br \/><a href=\"https:\/\/blog.logrocket.com\/langsmith-test-llms-ai-applications\/\" target=\"_blank\" rel=\"noopener\">https:\/\/blog.logrocket.com\/langsmith-test-llms-ai-applications\/<\/a><\/li>\n<li>Construire son RAG (Retrieval Augmented Generation) gr\u00c3\u00a2ce \u00c3\u00a0 langchain: L\u00e2\u0080\u0099exemple de l\u00e2\u0080\u0099Helpdesk d\u00e2\u0080\u0099OCTO &#8211; OCTO Talks !<br \/><a href=\"https:\/\/blog.octo.com\/le-chatbot-docto-langchain-rag-et-code-associe\" target=\"_blank\" rel=\"noopener\">https:\/\/blog.octo.com\/le-chatbot-docto-langchain-rag-et-code-associe<\/a><\/li>\n<li>LangChain cookbook | &#x1f99c;&#xfe0f;&#x1f517; LangChain<br \/><a href=\"https:\/\/python.langchain.com\/cookbook\" target=\"_blank\" rel=\"noopener\">https:\/\/python.langchain.com\/cookbook<\/a><\/li>\n<li>Retrieval Augmented Generation with Huggingface Transformers and Ray | Distributed Computing with Ray<br \/><a href=\"https:\/\/medium.com\/distributed-computing-with-ray\/retrieval-augmented-generation-with-huggingface-transformers-and-ray-b09b56161b1e\" target=\"_blank\" rel=\"noopener\">https:\/\/medium.com\/distributed-computing-with-ray\/retrieval-augmented-generation-with-huggingface-transformers-and-ray-b09b56161b1e<\/a><\/li>\n<li>Q&#038;A with RAG | &#x1f99c;&#xfe0f;&#x1f517; LangChain<br \/><a href=\"https:\/\/python.langchain.com\/docs\/expression_language\/cookbook\/retrieval\" target=\"_blank\" rel=\"noopener\">https:\/\/python.langchain.com\/docs\/expression_language\/cookbook\/retrieval<\/a><\/li>\n<li>Harnessing Retrieval Augmented Generation With Langchain | by Amogh Agastya | Better Programming<br \/><a href=\"https:\/\/betterprogramming.pub\/harnessing-retrieval-augmented-generation-with-langchain-2eae65926e82\" target=\"_blank\" rel=\"noopener\">https:\/\/betterprogramming.pub\/harnessing-retrieval-augmented-generation-with-langchain-2eae65926e82<\/a><\/li>\n<\/ul>\n",
            "protected": false
        },
        "excerpt": {
            "rendered": "<p>What to do once you identify the possible usages offered by AI? As a Product Owner, the risk is sometimes to pay lip service once&hellip; <\/p>\n<p class=\"text-center\"><a href=\"https:\/\/flaven.fr\/2024\/04\/transform-your-ideas-into-reality-develop-an-advanced-llm-ai-app-with-mistral-and-chatgpts-expert-guidance-and-comprehensive-prompts\/\" class=\"more-link\">Continue reading &rarr; <span class=\"screen-reader-text\">Transform Your Ideas into Reality: Develop an Advanced LLM AI App with Mistral and ChatGPT&#8217;s Expert Guidance and Comprehensive Prompts<\/span><\/a><\/p>\n",
            "protected": false
        },
        "author": 1
    },
    {
        "id": 12747,
        "link": "https:\/\/flaven.fr\/2024\/02\/simple-usecases-on-ai-prototyping-and-few-lessons-from-developing-a-webapp-api-llm-combination-for-nlp-tasks\/",
        "title": {
            "rendered": "Simple Usecases on AI Prototyping and few lessons from Developing a WebApp + API + LLM Combination for NLP Tasks"
        },
        "content": {
            "rendered": "<p>It&#8217;s not easy to document a process in progress, I am always late! Since what I am talking about has already become obsolete.<\/p>\n<p> <b>For this post, you can find all files for each project on my GitHub account. See <a href=\"https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ia_llms_usecases\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ia_llms_usecases<\/a><\/b><\/p>\n<p>Indeed, even though with the help of ChatGPT, I am in the process of making a prototype for an IA combination: &#8220;WebApp + API + LLM&#8221; to meet the AI needs that I have identified such as transcription, translation, generation using prompt and a bunch of various NLP tasks: Summary, NER, even Spelling Correction which has nothing to do with IA!<\/p>\n<p>This Prototype&#8217;s project I have already mentioned in small touches throughout the last posts on this blog and as evidenced by the GitHub directory: <a href=\"https:\/\/github.com\/bflaven\/ia_usages\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/bflaven\/ia_usages<\/a><\/p>\n<p>In this post, I will present two classic cases: News Topic Classification and Sentiment Analysis. As is often the case when we act, we find ourselves confronted with the reality of what needs to be done and the idea we have of it. What are the takeaways from these two POCs applying IA on Data.<\/p>\n<h2>What I learn from this experience?<\/h2>\n<p>I had already made such experiments but this time, somehow, I needed to present results and drew some conclusion. So, here they are:<\/p>\n<ol>\n<li>In a data-centric approach, data is key (dataset). The dataset goes through three stages: Bronze, Silver, Gold.<\/li>\n<li>80% of the work focuses on Evaluation Strategy, 20% Model Implementation<\/li>\n<li>The Data-centric approach can be summarized like so :<br \/>\n        <code>AI = Model + Data<\/code> where you mostly focus on data.\n    <\/li>\n<li><b>DATA IS A FUEL, as an input as an output<\/b><\/li>\n<\/ol>\n<p>It is quite peculiar because you can choose a model without breaking a sweat especially for classical issues such as News Topic Classification, Sentiment Analysis but you are going to bust your ass gathering the data and structuring it! In an almost caricatured manner, the workload is often distributed as follows:<\/p>\n<ul>\n<li>80% of the work is to consolidate the data and making change management. <\/li>\n<li>The resting 20% of the work is choosing Model and developing a combination <code>Webapp + API + LLM<\/code>. By the way, development that can be made by ChatGPT, Mistral, Codelama, llama2&#8230;. Choose your weapon. <\/li>\n<\/ul>\n<h2>Methodology: Some other concerns and few valuable lessons (MLOps).<\/h2>\n<p><b>There are also two major concerns to deal with: Confidentiality, Free.<\/b><\/p>\n<p>In News Topic Classification issue, USECASE_2, the fact of having replaced Mistral with ChatGPT, this was therefore done free of charge and securely.<\/p>\n<p>Finally, we followed what we call an ML-OPS process. Process which is defined as follows:<\/p>\n<blockquote><p>\n1. Ideation<br \/>\n2. Framing<br \/>\n3. Data Collection<br \/>\n4. Data Preparation<br \/>\n5. Feature Engineering<br \/>\n6. Modelling<br \/>\n7. Deployment<br \/>\n8. Change<br \/>\n9. Run\n<\/p><\/blockquote>\n<p><b>Here an illustration of the MLOps.<\/b><br \/>\n<img loading=\"lazy\" decoding=\"async\" width=\"600\" height=\"450\"\n    src=\"https:\/\/flaven.fr\/wp-content\/uploads\/2024\/02\/mlops-loop-en_small.png\"\n    alt=\"The Al Spectrum: Unveiling Layers of Intelligent Systems\"\n    title=\"The Al Spectrum: Unveiling Layers of Intelligent Systems\"><br \/>\nSource: <a href=\"https:\/\/ml-ops.org\/content\/mlops-principles\" target=\"_blank\" rel=\"noopener\">https:\/\/ml-ops.org\/content\/mlops-principles<\/a><\/p>\n<p><b>MLOps has much in common with Design Thinking Process<\/b><br \/>\n<img loading=\"lazy\" decoding=\"async\" width=\"600\" height=\"333\"\n        src=\"https:\/\/flaven.fr\/wp-content\/uploads\/2024\/02\/Five-steps-of-the-ideation-process_small.png\"\n        alt=\"Design Thinking Process\"\n        title=\"Design Thinking Process\"><\/p>\n<h2>Build a release, a must-have.<\/h2>\n<p>After, this framing and thinking, let do the acting. The time-to-market require to release a product as quick as possible by the end of few sprints even for a POC. Thanks to the LLM such as Mistral of ChatGTP, writing a rough combination rough for a &#8220;WebApp + API + LLM&#8221; is becoming more and more a piece of cake.<\/p>\n<p><b>You can check the directory &#8220;fastapi_usecase_1_sentiment_analysis&#8221;<\/b><\/p>\n<p><a href=\"https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ia_llms_usecases\/fastapi_usecase_1_sentiment_analysis\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ia_llms_usecases\/fastapi_usecase_1_sentiment_analysis<\/a><\/p>\n<p>With a series of ten or twenty prompts, you can jot a serious candidate. I beat recently my personal record with 50 prompts for a &#8220;WebApp + API + LLM&#8221; combination. The only reason why the number prompts inflates is that the number API\u2019s endpoints was higher and that induced an increase complexity for the Streamlit or Vite.js UX Webapp.<\/p>\n<h2>Find Dataset<\/h2>\n<p>Due to some confidentiality, I have substituted my datasets by some sample grabbed on Kaggle. Anyway, the principles are the same and the code is strictly identical.<\/p>\n<p>I found one by searching &#8220;News Topic Classification&#8221; and &#8220;Sentiment Analysis&#8221; on Kaggle<\/p>\n<ul>\n<li>News Topic Classification: <a href=\"https:\/\/www.kaggle.com\/datasets\/vrindakallu\/ag-news-topic-classification\" target=\"_blank\" rel=\"noopener\">https:\/\/www.kaggle.com\/datasets\/vrindakallu\/ag-news-topic-classification<\/a><\/li>\n<li>Sentiment Analysis: <a href=\"https:\/\/www.kaggle.com\/code\/robikscube\/sentiment-analysis-python-youtube-tutorial\/input\" target=\"_blank\" rel=\"noopener\">https:\/\/www.kaggle.com\/code\/robikscube\/sentiment-analysis-python-youtube-tutorial\/input<\/a><\/li>\n<\/ul>\n<h2>Let&#8217;s dig the usecases<\/h2>\n<p>The first case is called <b>usecase_1_sentiment_analysis<\/b>, a very classical one. You got text, most of the time comments and you want to classify if the text is negative or positive. <\/p>\n<p>My only issue was that the text was in French but for educational, i have swap the model and give now an English sample and a model trained on English. The French Model is still in the code, commented, is based on &#8220;distilcamembert-base-sentiment&#8221; found on <a href=\"https:\/\/huggingface.co\/cmarkea\/distilcamembert-base-sentiment\" target=\"_blank\" rel=\"noopener\">https:\/\/huggingface.co\/cmarkea\/distilcamembert-base-sentiment<\/a><\/p>\n<p>The English model is <a href=\"https:\/\/huggingface.co\/lxyuan\/distilbert-base-multilingual-cased-sentiments-student\" target=\"_blank\" rel=\"noopener\">https:\/\/huggingface.co\/lxyuan\/distilbert-base-multilingual-cased-sentiments-student<\/a><\/p>\n<p><b>I have also drastically reduced the sample to 1000 rows for the Sentiment Analysis because it works easily on my Mac.<\/b><\/p>\n<p>See the sample at <a href=\"https:\/\/www.kaggle.com\/code\/robikscube\/sentiment-analysis-python-youtube-tutorial\/input\" target=\"_blank\" rel=\"noopener\">https:\/\/www.kaggle.com\/code\/robikscube\/sentiment-analysis-python-youtube-tutorial\/input<\/a><\/p>\n<p>The second case is more sophisticated than the first one: <b>usecase_2_text_classification<\/b>. It is an issue on text classification e.g. Posts made on Social Networks have to re-categorized. I have made 2 user stories on this issue that I have turned to prompts sent to Mistral.<\/p>\n<p><b>What is amazing is that with LMM is that as far you have created an API that is able to query with a prompt a LLM such as Mistral then you are good to go to implement whatever user story you want! See below, two prompts slightly different but the mechanic remains the same.<\/b><\/p>\n<pre>\r\n     V1 choice in a limited number of predefined categories\r\n    # first_prompt = ChatPromptTemplate.from_template(\r\n    #     \"Act as a highly intelligent news chatbot and classify the given news text into one of the following categories only: France, Europe Africa, America, Asia-Pacific, Middle East, Sports, Economy, Technology, Culture, Environment. Do not code. Return only one word answer with only the category name that the given news text belongs to. In the output, return the result in a field named \\\"category_predicted:\\\" and return the comment in the field \\\"category_decision:\\\" in a python Dictionary.\t News text: {news}?\"\r\n    # ) \r\n\r\n    # V2 no choice let the LLM defined the category\r\n    first_prompt = ChatPromptTemplate.from_template(\r\n        \"Act as a highly intelligent news chatbot and classify the given news text into the most adequate single category. Do not code. Return only one word answer with only the category name that the given news text belongs to. In the output, return the result in a field named \\\"category_predicted:\\\" and return the comment in the field \\\"category_decision:\\\" in a python Dictionary.\t News text: {news}?\"\r\n    )  \r\n<\/pre>\n<h1>Illustrations<\/h1>\n<p>I was looking for illustrations for &#8220;Data Science Process Lifecycle&#8221; and also to have a big picture on the connection between machine learning, AI&#8230;etc<\/p>\n<p>I found these 2 images that I found quite interesting mostly because it is not ugly and incidentally because it is straightforward.<\/p>\n<p><b>Data Science Lifecycle: This is pretty much all the stages of transformation that you will go through you and your data before learning anything from it.<\/b><br \/>\n<img loading=\"lazy\" decoding=\"async\" width=\"600\" height=\"603\" src=\"https:\/\/flaven.fr\/wp-content\/uploads\/2024\/02\/data_science_process_lifecycle_chart_small.png\" alt=\"Data Science Lifecycle\" title=\"Data Science Lifecycle\"><\/p>\n<p><b>A classic but effective image to locate the different areas when we talk about AI.<\/b><br \/>\n<img loading=\"lazy\" decoding=\"async\" width=\"600\" height=\"511\" src=\"https:\/\/flaven.fr\/wp-content\/uploads\/2024\/02\/spectrum_conceptual-framework-of-ai-machine-learning-deep-learning-and-generative-ai_small.png\" alt=\"The Al Spectrum: Unveiling Layers of Intelligent Systems\" title=\"The Al Spectrum: Unveiling Layers of Intelligent Systems\"><\/p>\n<p>I grab these pictures from these sources:<\/p>\n<ol>\n<li>Understanding the Data Science Lifecycle: <a href=\"https:\/\/www.sudeep.co\/data-science\/2018\/02\/09\/Understanding-the-Data-Science-Lifecycle.html\" target=\"_blank\" rel=\"noopener\">https:\/\/www.sudeep.co\/data-science\/2018\/02\/09\/Understanding-the-Data-Science-Lifecycle.html<\/a><\/li>\n<li>Machine Learning: A Quick Introduction and Five Core Steps: <a href=\"https:\/\/centricconsulting.com\/blog\/machine-learning-a-quick-introduction-and-five-core-steps\/\" target=\"_blank\" rel=\"noopener\">https:\/\/centricconsulting.com\/blog\/machine-learning-a-quick-introduction-and-five-core-steps\/<\/a><\/li>\n<li>Natural Language Processing and Machine Learning: <a href=\"https:\/\/www.encora.com\/insights\/natural-language-processing-and-machine-learning\" target=\"_blank\" rel=\"noopener\">https:\/\/www.encora.com\/insights\/natural-language-processing-and-machine-learning<\/a>\n<\/li>\n<li>The ai spectrum: unveilling layers of intelligent system: <a href=\"https:\/\/www.scribbr.com\/ai-tools\/deep-learning\/\" target=\"_blank\" rel=\"noopener\">https:\/\/www.scribbr.com\/ai-tools\/deep-learning\/<\/a><\/li>\n<\/ol>\n<h2>Presenting the result<\/h2>\n<p>In addition, I have made a jupyter notebook to easily present the ML process especially the data exploitation.<\/p>\n<p>You can check the file <code>usecase_1_sentiment_analysis.ipynb<\/code>. Below, you have the command to leverage on the anaconda environment created for the usecase.<\/p>\n<p>The jupyter notebook is available at <a href=\"https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ia_llms_usecases\/usecase_1_sentiment_analysis\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ia_llms_usecases\/usecase_1_sentiment_analysis<\/a><\/p>\n<p><b>How to launch a jupyter notebook on a specific environment?<\/b><\/p>\n<pre>\r\n# In base launch the specific sentiment_analysis with this command\r\npython -m ipykernel install --user --name=sentiment_analysis\r\n\r\n# Activate the env sentiment_analysis\r\nsource activate sentiment_analysis\r\n\r\n# Launch the jupyter notebook in this env sentiment_analysis\r\njupyter notebook\r\n\r\n# Create the virtual environment\r\nconda create -n 'environment_name'\r\n\r\n# Activate the virtual environment\r\nconda activate 'environment_name'\r\n\r\n# Make sure that ipykernel is installed\r\npip install --user ipykernel\r\n\r\n# Add the new virtual environment to Jupyter\r\npython -m ipykernel install --user --name='environment_name'\r\n\r\n# To list existing Jupyter virtual environments\r\njupyter kernelspec list\r\n\r\n# To list existing conda environments\r\nconda env list\r\n\r\n## To remove conda environment\r\nconda env remove -n 'environment_name'\r\n\r\n## To remove the environment from Jupyter\r\njupyter kernelspec uninstall 'environment_name'\r\n<\/pre>\n<p><b>Create an anaconda environment<\/b><\/p>\n<pre>\r\n[env]\r\n# Conda Environment\r\nconda create --name sentiment_analysis python=3.9.13\r\nconda info --envs\r\nsource activate sentiment_analysis\r\nconda deactivate\r\n\r\n# if needed to remove\r\nconda env remove -n [NAME_OF_THE_CONDA_ENVIRONMENT]\r\nconda env remove -n sentiment_analysis\r\nconda env remove -n faststream_kafka\r\n\r\n\r\n\r\n# update conda \r\nconda update -n base -c defaults conda\r\n\r\n# to export requirements\r\npip freeze > requirements.txt\r\n\r\n# to install\r\npip install -r requirements.txt\r\n\r\n\r\n<\/pre>\n<p><H2>More infos<\/H2><\/p>\n<ul>\n<li>Postman<br \/><a href=\"https:\/\/www.postman.com\/postman-student-programs\/workspace\/ollama-api\/documentation\/21521806-f48dc31a-a9f1-4dad-9082-fd07f5cd2fda\" target=\"_blank\" rel=\"noopener\">https:\/\/www.postman.com\/postman-student-programs\/workspace\/ollama-api\/documentation\/21521806-f48dc31a-a9f1-4dad-9082-fd07f5cd2fda<\/a><\/li>\n<li>GitHub &#8211; ggerganov\/llama.cpp: Port of Facebook&#8217;s LLaMA model in C\/C++<br \/><a href=\"https:\/\/github.com\/ggerganov\/llama.cpp\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/ggerganov\/llama.cpp<\/a><\/li>\n<li>Easy as Ollama: Running Large Language Models Locally with a Elegant Web UI | by Rob \u015aliwa | Medium<br \/><a href=\"https:\/\/medium.com\/@robjsliwa_71070\/easy-as-ollama-running-large-language-models-locally-with-a-elegant-web-ui-af3255b18141\" target=\"_blank\" rel=\"noopener\">https:\/\/medium.com\/@robjsliwa_71070\/easy-as-ollama-running-large-language-models-locally-with-a-elegant-web-ui-af3255b18141<\/a><\/li>\n<li>GitHub &#8211; microsoft\/classy-fire: Classy-fire is multiclass text classification approach leveraging OpenAI LLM model APIs optimally using clever parameter tuning and prompting.<br \/><a href=\"https:\/\/github.com\/microsoft\/classy-fire\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/microsoft\/classy-fire<\/a><\/li>\n<li>Six Ways of Running Large Language Models (LLMs) Locally (January 2024)<br \/><a href=\"https:\/\/kleiber.me\/blog\/2024\/01\/07\/six-ways-running-llm-locally\/\" target=\"_blank\" rel=\"noopener\">https:\/\/kleiber.me\/blog\/2024\/01\/07\/six-ways-running-llm-locally\/<\/a><\/li>\n<li>Title Not Found<br \/><a href=\"https:\/\/github.com\/search?q=ollama+python+language%3APython&#038;type=repositories&#038;l=Python&#038;p=2\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/search?q=ollama+python+language%3APython&#038;type=repositories&#038;l=Python&#038;p=2<\/a><\/li>\n<li>GPT4All<br \/><a href=\"https:\/\/gpt4all.io\/index.html\" target=\"_blank\" rel=\"noopener\">https:\/\/gpt4all.io\/index.html<\/a><\/li>\n<li>Build your own RAG and run it locally: Langchain + Ollama + Streamlit | by Duy Huynh | Medium<br \/><a href=\"https:\/\/medium.com\/@vndee.huynh\/build-your-own-rag-and-run-it-locally-langchain-ollama-streamlit-181d42805895\" target=\"_blank\" rel=\"noopener\">https:\/\/medium.com\/@vndee.huynh\/build-your-own-rag-and-run-it-locally-langchain-ollama-streamlit-181d42805895<\/a><\/li>\n<li>Few Shot Prompting with CodeLlama, LangChain, and MySQL | by Praveen Yerneni | Medium<br \/><a href=\"https:\/\/medium.com\/@yernenip\/few-shot-prompting-with-codellama-langchain-and-mysql-94020ee16a08\" target=\"_blank\" rel=\"noopener\">https:\/\/medium.com\/@yernenip\/few-shot-prompting-with-codellama-langchain-and-mysql-94020ee16a08<\/a><\/li>\n<li>Run LLMs locally | &#x1f99c;&#xfe0f;&#x1f517; Langchain<br \/><a href=\"https:\/\/python.langchain.com\/docs\/guides\/local_llms\" target=\"_blank\" rel=\"noopener\">https:\/\/python.langchain.com\/docs\/guides\/local_llms<\/a><\/li>\n<li>Ollama &#8211; running large language models on your machine | Unmesh Gundecha<br \/><a href=\"https:\/\/unmesh.dev\/post\/ollama\/\" target=\"_blank\" rel=\"noopener\">https:\/\/unmesh.dev\/post\/ollama\/<\/a><\/li>\n<li>Mixtral-46.7B &#8211; a Hugging Face Space by ehristoforu<br \/><a href=\"https:\/\/huggingface.co\/spaces\/ehristoforu\/mixtral-46.7b-chat\" target=\"_blank\" rel=\"noopener\">https:\/\/huggingface.co\/spaces\/ehristoforu\/mixtral-46.7b-chat<\/a><\/li>\n<li>How to Run Mixtral 8x7B Locally &#8211; Step by Step Tutorial<br \/><a href=\"https:\/\/anakin.ai\/blog\/how-to-run-mixtral-8x7b-locally\/\" target=\"_blank\" rel=\"noopener\">https:\/\/anakin.ai\/blog\/how-to-run-mixtral-8x7b-locally\/<\/a><\/li>\n<li>Create your first LLM playground | liteLLM<br \/><a href=\"https:\/\/docs.litellm.ai\/docs\/tutorials\/first_playground\" target=\"_blank\" rel=\"noopener\">https:\/\/docs.litellm.ai\/docs\/tutorials\/first_playground<\/a><\/li>\n<li>Mixtral 8x7B en Local : Entra\u00eenez votre LLM avec vos Propres Donn\u00e9es | Scalastic &#x1f468;&#x1f3fb;&#x200d;&#x1f4bb;<br \/><a href=\"https:\/\/scalastic.io\/mixtral-ollama-llamaindex-llm\/\" target=\"_blank\" rel=\"noopener\">https:\/\/scalastic.io\/mixtral-ollama-llamaindex-llm\/<\/a><\/li>\n<li>Running Mixtral 8&#215;7 locally with LlamaIndex and Ollama | by LlamaIndex | Dec, 2023 | LlamaIndex Blog<br \/><a href=\"https:\/\/blog.llamaindex.ai\/running-mixtral-8x7-locally-with-llamaindex-e6cebeabe0ab\" target=\"_blank\" rel=\"noopener\">https:\/\/blog.llamaindex.ai\/running-mixtral-8&#215;7-locally-with-llamaindex-e6cebeabe0ab<\/a><\/li>\n<li>Local LLM in the Browser Powered by Ollama | by Andrew Nguonly | Medium<br \/><a href=\"https:\/\/medium.com\/@andrewnguonly\/local-llm-in-the-browser-powered-by-ollama-236817f335da\" target=\"_blank\" rel=\"noopener\">https:\/\/medium.com\/@andrewnguonly\/local-llm-in-the-browser-powered-by-ollama-236817f335da<\/a><\/li>\n<li>Ollama: Easily run LLMs locally \u2014 Klu<br \/><a href=\"https:\/\/klu.ai\/glossary\/ollama\" target=\"_blank\" rel=\"noopener\">https:\/\/klu.ai\/glossary\/ollama<\/a><\/li>\n<li>Ollama: Running GGUF Models from Hugging Face | Mark Needham<br \/><a href=\"https:\/\/www.markhneedham.com\/blog\/2023\/10\/18\/ollama-hugging-face-gguf-models\/\" target=\"_blank\" rel=\"noopener\">https:\/\/www.markhneedham.com\/blog\/2023\/10\/18\/ollama-hugging-face-gguf-models\/<\/a><\/li>\n<li>Running a Hugging Face Large Language Model (LLM) locally on my laptop | Mark Needham<br \/><a href=\"https:\/\/www.markhneedham.com\/blog\/2023\/06\/23\/hugging-face-run-llm-model-locally-laptop\/\" target=\"_blank\" rel=\"noopener\">https:\/\/www.markhneedham.com\/blog\/2023\/06\/23\/hugging-face-run-llm-model-locally-laptop\/<\/a><\/li>\n<li>Integrating Llama 2 with Hugging Face and Langchain&#x1f999;<br \/><a href=\"https:\/\/blog.futuresmart.ai\/integrating-llama-2-with-hugging-face-and-langchain\" target=\"_blank\" rel=\"noopener\">https:\/\/blog.futuresmart.ai\/integrating-llama-2-with-hugging-face-and-langchain<\/a><\/li>\n<li>GitHub &#8211; dennisypan\/Quick-N-Dirty-Sentiment-Analysis: Suppose you got a CSV file with rows of distinct comments and 5-stars ratings on a business (e.g. a restaurant from Yelp).  This tool will process data from this CSV input file to (1) produce an output CSV file giving each row a &#8220;Sentiment Label&#8221; and &#8220;Sentiment Score&#8221;, and (2) a statement on Command Prompt (Windows) describing the overall sentiment (Positive, Neutral, Negative) of the business.<br \/><a href=\"https:\/\/github.com\/dennisypan\/Quick-N-Dirty-Sentiment-Analysis\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/dennisypan\/Quick-N-Dirty-Sentiment-Analysis<\/a><\/li>\n<li>GitHub &#8211; raheem-m\/NYT-API-Comment-Sentiment-Analysis: This is a python program that hits the NYT article search API as well as the Community API to retrieve comments from a set of articles searched from user input. Sentiment analysis is then applied to the first 25 comments, then output to a csv file.<br \/><a href=\"https:\/\/github.com\/raheem-m\/NYT-API-Comment-Sentiment-Analysis\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/raheem-m\/NYT-API-Comment-Sentiment-Analysis<\/a><\/li>\n<li>GitHub &#8211; marcellobarile\/multilang-sentiment: Multi language AFINN-based sentiment analysis for Node.js.<br \/><a href=\"https:\/\/github.com\/marcellobarile\/multilang-sentiment\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/marcellobarile\/multilang-sentiment<\/a><\/li>\n<li>Problem-solving with ML: automatic document classification | Google Cloud Blog<br \/><a href=\"https:\/\/cloud.google.com\/blog\/products\/ai-machine-learning\/problem-solving-with-ml-automatic-document-classification\" target=\"_blank\" rel=\"noopener\">https:\/\/cloud.google.com\/blog\/products\/ai-machine-learning\/problem-solving-with-ml-automatic-document-classification<\/a><\/li>\n<li>Text Classification &#8211; &#x26a1;LangChain + Mixtral8X7B&#x26a1; | Kaggle<br \/><a href=\"https:\/\/www.kaggle.com\/code\/swathysekar\/text-classification-langchain-mixtral8x7b\" target=\"_blank\" rel=\"noopener\">https:\/\/www.kaggle.com\/code\/swathysekar\/text-classification-langchain-mixtral8x7b<\/a><\/li>\n<li>GitHub &#8211; kodiks\/turkish-news-classification: Turkish News Category Classification Tutorial<br \/><a href=\"https:\/\/github.com\/kodiks\/turkish-news-classification\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/kodiks\/turkish-news-classification<\/a><\/li>\n<li>HuggingFace T\u00fcrk\u00e7e Veri K\u00fcmeleri. \u201cDataset is power\u201d! | by Yavuz K\u00f6me\u00e7o\u011flu | Kodiks | Medium<br \/><a href=\"https:\/\/medium.com\/kodiks\/huggingface-turkce-verikumeleri-6d213dd63966\" target=\"_blank\" rel=\"noopener\">https:\/\/medium.com\/kodiks\/huggingface-turkce-verikumeleri-6d213dd63966<\/a><\/li>\n<li>Turkish News Category Classification Tutorial | by Serdar Akyol | Kodiks | Medium<br \/><a href=\"https:\/\/medium.com\/kodiks\/turkish-news-category-classification-tutorial-6b9317b49915\" target=\"_blank\" rel=\"noopener\">https:\/\/medium.com\/kodiks\/turkish-news-category-classification-tutorial-6b9317b49915<\/a><\/li>\n<li>Title Not Found<br \/><a href=\"https:\/\/github.com\/susanli2016\/Machine-Learning-with-Python\/blob\/master\/Consumer_complaints.ipynb\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/susanli2016\/Machine-Learning-with-Python\/blob\/master\/Consumer_complaints.ipynb<\/a><\/li>\n<li>Amazon Fine Food Reviews | Kaggle<br \/><a href=\"https:\/\/www.kaggle.com\/datasets\/snap\/amazon-fine-food-reviews\/code?datasetId=18\" target=\"_blank\" rel=\"noopener\">https:\/\/www.kaggle.com\/datasets\/snap\/amazon-fine-food-reviews\/code?datasetId=18<\/a><\/li>\n<li>Deep Learning For NLP: Zero To Transformers &#038; BERT | Kaggle<br \/><a href=\"https:\/\/www.kaggle.com\/code\/tanulsingh077\/deep-learning-for-nlp-zero-to-transformers-bert\" target=\"_blank\" rel=\"noopener\">https:\/\/www.kaggle.com\/code\/tanulsingh077\/deep-learning-for-nlp-zero-to-transformers-bert<\/a><\/li>\n<li>Building Powerful NLP Library in Python for 2024 | by Fareed Khan | Dec, 2023 | Level Up Coding<br \/><a href=\"https:\/\/levelup.gitconnected.com\/how-i-created-the-most-powerful-nlp-library-in-python-c26d08a55809\" target=\"_blank\" rel=\"noopener\">https:\/\/levelup.gitconnected.com\/how-i-created-the-most-powerful-nlp-library-in-python-c26d08a55809<\/a><\/li>\n<li>Gemini &#8211; Google DeepMind<br \/><a href=\"https:\/\/deepmind.google\/technologies\/gemini\/#introduction\" target=\"_blank\" rel=\"noopener\">https:\/\/deepmind.google\/technologies\/gemini\/#introduction<\/a><\/li>\n<li>GitHub &#8211; rasbt\/LLMs-from-scratch: Implementing a ChatGPT-like LLM from scratch, step by step<br \/><a href=\"https:\/\/github.com\/rasbt\/LLMs-from-scratch\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/rasbt\/LLMs-from-scratch<\/a><\/li>\n<li>Build Your Own Large Language model (LLM) Model with OpenAI using Microsoft Excel file<br \/><a href=\"https:\/\/decube.substack.com\/p\/build-your-own-large-language-model\" target=\"_blank\" rel=\"noopener\">https:\/\/decube.substack.com\/p\/build-your-own-large-language-model<\/a><\/li>\n<li>The 40-hour LLM application roadmap: Learn to build your own LLM applications from scratch | Data Science Dojo<br \/><a href=\"https:\/\/datasciencedojo.com\/blog\/build-custom-llm-application\/\" target=\"_blank\" rel=\"noopener\">https:\/\/datasciencedojo.com\/blog\/build-custom-llm-application\/<\/a><\/li>\n<li>How to create a private ChatGPT with your own data | by Mick Vleeshouwer | Medium<br \/><a href=\"https:\/\/medium.com\/@imicknl\/how-to-create-a-private-chatgpt-with-your-own-data-15754e6378a1\" target=\"_blank\" rel=\"noopener\">https:\/\/medium.com\/@imicknl\/how-to-create-a-private-chatgpt-with-your-own-data-15754e6378a1<\/a><\/li>\n<li>Title Not Found<br \/><a href=\"https:\/\/github.com\/openai\/openai-cookbook\/blob\/main\/examples\/Question_answering_using_embeddings.ipynb\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/openai\/openai-cookbook\/blob\/main\/examples\/Question_answering_using_embeddings.ipynb<\/a><\/li>\n<li>GitHub &#8211; stochasticai\/xTuring: Build, customize and control you own LLMs. From data pre-processing to fine-tuning, xTuring provides an easy way to personalize open-source LLMs. Join our discord community: https:\/\/discord.gg\/TgHXuSJEk6<br \/><a href=\"https:\/\/github.com\/stochasticai\/xturing\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/stochasticai\/xturing<\/a><\/li>\n<\/ul>\n",
            "protected": false
        },
        "excerpt": {
            "rendered": "<p>It&#8217;s not easy to document a process in progress, I am always late! Since what I am talking about has already become obsolete. For this&hellip; <\/p>\n<p class=\"text-center\"><a href=\"https:\/\/flaven.fr\/2024\/02\/simple-usecases-on-ai-prototyping-and-few-lessons-from-developing-a-webapp-api-llm-combination-for-nlp-tasks\/\" class=\"more-link\">Continue reading &rarr; <span class=\"screen-reader-text\">Simple Usecases on AI Prototyping and few lessons from Developing a WebApp + API + LLM Combination for NLP Tasks<\/span><\/a><\/p>\n",
            "protected": false
        },
        "author": 1
    },
    {
        "id": 12740,
        "link": "https:\/\/flaven.fr\/2024\/01\/navigating-the-data-landscape-exploring-key-elements-of-superset-and-kafka-for-a-real-time-analytics-platform\/",
        "title": {
            "rendered": "Navigating the Data Landscape: Exploring Key Elements of Superset and Kafka for a Real-Time Analytics Platform"
        },
        "content": {
            "rendered": "<p>I changed the nature of my personal sprint objective, moving away slightly from AI concerns to reconnect with more general considerations about Data and its processing: from collection to its visualization through its &#8220;processing&#8221;. Ultimately, of course, this treatment could be injected with AI or ML. As always, when we start thinking about such a vast subject, the first question is what do we want to land on to define the scope? In this case, I wondered how to approach the question of data.<\/p>\n<p>So, according to me and after compiling several resources, finally the two things that seem most important to me for now:<\/p>\n<ul>\n<li>How can I improve visualisation of existing data e.g csv for instance?<\/li>\n<li>What are the ways to improve data collection?<\/li>\n<\/ul>\n<p> <b>For this post, you can find all files for each project on my GitHub account. See <a href=\"https:\/\/github.com\/bflaven\/BlogArticlesExamples\/tree\/master\/how_to_use_superset_kafka_agile2\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/bflaven\/BlogArticlesExamples\/tree\/master\/how_to_use_superset_kafka_agile2<\/a><\/b><\/p>\n<h2>Key-ideas that should drives a POC<\/h2>\n<p>Like always, I read some stuff that I found inspiring and note everything down. Sometimes, I found some consolations and some advice that act like mantras when you start a POC to avoid the WIP&#8217;s hell.<\/p>\n<blockquote><p>Learning is an active process. We learn by doing. Only knowledge that is used sticks in your mind. &#8211; Dale Carnegie<\/p><\/blockquote>\n<p><b>For records, some good stuff from Agile2<\/b><\/p>\n<p>Apparently, Agile is dead long live to Agile2.<\/p>\n<p>I just read this article: <a href=\"https:\/\/medium.com\/developer-rants\/agile-has-failed-officially-8136b0522c49\" target=\"_blank\" rel=\"noopener\">https:\/\/medium.com\/developer-rants\/agile-has-failed-officially-8136b0522c49<\/a><\/p>\n<p>Funny, this reminds me of several things:<br \/>\nLike any belief or ideology, it is beneficial to question\/criticize any &#8220;dominant&#8221; model of thought. Quite provocative and indeed, sensible for two reasons:<\/p>\n<ol>\n<li>Agile without leadership is worthless, it amounts to submitting to stupid and pointless formalism \ud83d\ude42<\/li>\n<li>Agile 2 is also a clever way to sell even more, it&#8217;s a bit like Persil laundry detergent, a new formula. We sell you the same product but with extra soul. <\/li>\n<\/ol>\n<p><b>A good reminder to meditate. <\/b><\/p>\n<blockquote><p>At some point, a project must produce a final product. <\/p><\/blockquote>\n<p><b>Some other excerpts from the Agile2 core values on some specific aspects for project management. <\/b><\/p>\n<p><b>(i) Planning, Transition &#038; Transformation<\/b><\/p>\n<ul>\n<li>Any initiative requires both a vision or goal, and a flexible, steerable, outcome-oriented plan. <\/li>\n<li>Any significant transformation is mostly a learning journey \u2013 not merely a process change. <\/li>\n<li>Product development is mostly a learning journey \u2013 not merely an &#8220;implementation.&#8221;<\/li>\n<\/ul>\n<p><b>(ii) Product, Portfolio &#038; Stakeholders<\/b><\/p>\n<ul>\n<li>Obtain feedback from the market and stakeholders continuously.<\/li>\n<li>Work iteratively in small batches.<\/li>\n<li>The only proof of value is a business outcome.<\/li>\n<li>Organizations need an \u201cinception framework\u201d tailored to their needs.<\/li>\n<li>Create documentation to share and deepen understanding.<\/li>\n<\/ul>\n<p><b>(iii) Continuous Improvement<\/b><\/p>\n<ul>\n<li>Place limits on things that cause drag.<\/li>\n<li>Integrate early and often.<\/li>\n<\/ul>\n<h2>Streamline the data analytics flow&#8230;<\/h2>\n<p>Anyway, let&#8217;s get back to the main course. I was about to make a complete benchmark among the market solutions: Superset, Redash and even ClickHouse. But, finally Superset is enough for my product discovery.<\/p>\n<p>I was looking for some ideas on how to improve data analytics flow. Indeed, it is always useful &#8220;to set up a system that allows you to get a deeper understanding of the behaviour of your customers&#8221;.<\/p>\n<p>Source: <a href=\"https:\/\/xebia.com\/blog\/real-time-analytics-divolte-kafka-druid-superset\/\" target=\"_blank\" rel=\"noopener\">https:\/\/xebia.com\/blog\/real-time-analytics-divolte-kafka-druid-superset\/<\/a><\/p>\n<p>Having an alternative pipeline that could be called &#8220;real-time analytics platform&#8221; can help to better perform:<\/p>\n<p><b>Descriptive analysis:<\/b> either the act of analyzing the data and describing what they say at a given time;<\/p>\n<p><b>Predictive analysis:<\/b> predicting a potential result based on data extracted from past or current activities.<\/p>\n<p>Source: <a href=\"https:\/\/betterprogramming.pub\/building-an-order-delivery-analytics-application-with-fastapi-kafka-apache-pinot-and-dash-part-ca276a3ee631\" target=\"_blank\" rel=\"noopener\">https:\/\/betterprogramming.pub\/building-an-order-delivery-analytics-application-with-fastapi-kafka-apache-pinot-and-dash-part-ca276a3ee631<\/a><\/p>\n<p>Based on these 2 posts, I decide to go for :<\/p>\n<ol>\n<li>Improve visualisation of existing data with Superset.<\/li>\n<li>Explore quickly Kafka to improve data collection.<\/li>\n<\/ol>\n<h2>1. Superset with Docker<\/h2>\n<p>Superset is the most intuitive tool that I found to improve visualisation. Here is a quick way to install and manage Superset with Docker.<\/p>\n<pre>\r\n# go to path\r\ncd \/Users\/brunoflaven\/Documents\/01_work\/blog_articles\/how_to_use_superset\/\r\n\r\n\r\n# command to open docker\r\nopen -a docker\r\n\r\n# clone the dir\r\ngit clone https:\/\/github.com\/apache\/superset.git superset\r\n\r\n\r\n# get into the dir\r\ncd superset\r\n\r\n\r\n# get the superset stuff \r\ndocker compose -f docker-compose-non-dev.yml pull\r\n\r\n# start the superset stuff \r\ndocker compose -f docker-compose-non-dev.yml up\r\n\r\n# start using Superset\r\n# http:\/\/localhost:8088\r\n# username: admin\r\n# password: admin\r\n<\/pre>\n<h2>2. Connecting Superset to Databases<\/h2>\n<p>You need to have some databases e.g. <code>mariadb<\/code>, <code>mongodb<\/code>, <code>mysql<\/code>, <code>postgresql<\/code> installed on your machine to leverage on a database. To be sure to connect Superset to your local database, you need to use the hostname <code>docker.for.mac.host.internal<\/code> instead of <code>localhost<\/code>.<\/p>\n<p>On mac, the best way to do so: install databases, it is to use homebrew. Here are the commands  to install databases.<\/p>\n<pre>\r\n\r\n# list services for database\r\nbrew services list\r\n\r\n\r\n# classical commands before install\r\nbrew update\r\nbrew upgrade\r\nbrew doctor\r\n<\/pre>\n<p>To Install Homebrew if you haven&#8217;t already: https:\/\/brew.sh\/<\/p>\n<pre>\r\n\/bin\/bash -c \"$(curl -fsSL https:\/\/raw.githubusercontent.com\/Homebrew\/install\/main\/install.sh)\"\r\n\r\n# Update the Homebrew formulae:\r\nbrew update\r\n<\/pre>\n<p><b>2.1 MARIADB<\/b><br \/>\nMariaDB is an open-source, community-developed relational database<br \/>\nmanagement system (RDBMS) that serves as a drop-in replacement for MySQL.<br \/>\nIt offers a robust and flexible SQL engine with features such as stored<br \/>\nprocedures, views, subqueries, and triggers. <\/p>\n<p><b>Advantages of MariaDB:<\/b><\/p>\n<ol>\n<li><b>Compatibility:<\/b> MariaDB is highly compatible with MySQL, making it easy<br \/>\nto migrate existing databases without having to rewrite code or modify<br \/>\napplications.<\/li>\n<li><b>Performance:<\/b> MariaDB offers improved performance compared to MySQL<br \/>\nthrough enhancements like optimistic optimization and asynchronous<br \/>\nreplication. This results in faster query processing and reduced latency<br \/>\nin real-time environments.<\/li>\n<li><b>Scalability:<\/b> MariaDB is designed for scalability, with features such as<br \/>\npartitioning that can help handle large datasets efficiently while<br \/>\nensuring optimal performance.<\/li>\n<\/ol>\n<pre>\r\n# Managing the mariadb database\r\n\r\n# mariadb\r\nbrew search mariadb\r\nbrew install mariadb\r\nbrew services start mariadb\r\nbrew services stop mariadb\r\n\r\n# connect to mariadb (no password)\r\nmysql\r\nmysql -u brunoflaven \r\n\r\n# create a root user with all privileges\r\nCREATE USER 'root'@'hostname' IDENTIFIED BY 'root';\r\n# CREATE USER 'root'@'%' IDENTIFIED BY 'root';\r\nSELECT USER,is_role,default_role FROM mysql.user;\r\nGRANT ALL PRIVILEGES ON *.* TO 'root'@localhost IDENTIFIED BY 'root';\r\nFLUSH PRIVILEGES;\r\nSHOW GRANTS FOR 'root'@localhost;\r\n\r\n# connection infos\r\n# select mysql\r\n# add port 3306\r\n# add host docker.for.mac.host.internal or 127.0.0.1\r\n# db_name : mydatabase_try_mariadb\r\n# user: root\r\n# pwd: root\r\n\r\n\r\n\r\n# useful commands\r\n# create databases\r\nCREATE DATABASE try_mariadb;\r\nUSE try_mariadb;\r\nCREATE TABLE testtable\r\n(\r\n id int not null primary key,\r\n name varchar(20) not null,\r\n lastupdate timestamp not null\r\n );\r\n\r\n# insert\r\nINSERT INTO testtable\r\n (id, name, lastupdate)\r\n values (1,'Sample name','2022-09-22 18:53');\r\n\r\nINSERT INTO testtable\r\n (id, name, lastupdate)\r\n values (2,'Sample name 2','2022-09-22 18:54');\r\n\r\n# update\r\nUPDATE testtable set name = 'updated name' where id=1;\r\n\r\n# delete one record with the id equal to 4\r\nDELETE FROM testtable where id = 4;\r\n\r\n# select all content from the table testtable \r\nSELECT * FROM testtable;\r\n\r\n# drop\r\nDROP TABLE testtable;\r\n\r\n# empty\r\nTRUNCATE testtable;\r\n\r\n\r\n\r\n<\/pre>\n<p><b>2.2 POSTGRES<\/b><\/p>\n<p>PostgreSQL (Postgres) is a powerful, open-source object-relational<br \/>\ndatabase system with a strong emphasis on reliability, data integrity, and<br \/>\ncorrectness. It supports a wide range of data types, including<br \/>\ngeographical data, large objects such as images, JSON, and XML documents,<br \/>\nand advanced features like stored procedures, triggers, and rules.<\/p>\n<p><b>Advantages of PostgreSQL:<\/b><\/p>\n<ol>\n<li><b>Robustness:<\/b> Postgres is known for its robustness in handling complex<br \/>\nqueries, concurrency, and reliability. It follows the ACID (Atomicity,<br \/>\nConsistency, Isolation, Durability) principles to ensure data integrity.<\/li>\n<li><b>Extensibility:<\/b> Postgres offers a rich ecosystem with built-in support<br \/>\nfor various languages and data types. Its plugin architecture allows for<br \/>\nseamless integration of new features and functionality without altering<br \/>\nthe core system.<\/li>\n<li><b>Compatibility:<\/b> PostgreSQL is highly compatible with many popular<br \/>\ndatabase systems, including SQL Server, Oracle, MySQL, and DB2. This makes<br \/>\nit easy to migrate existing applications oruser<\/li>\n<\/ol>\n<pre>\r\n\r\n# install and start postgresql with homebrew \r\nbrew search postgresql\r\nbrew install postgresql\r\nbrew services start postgresql\r\nbrew services stop postgresql\r\n\r\n# connect to postgres\r\npsql postgres\r\n\r\n# way_1 to connect to postgresql\r\n# in the console\r\nCREATEUSER -s postgres\r\n# in the postgres client\r\nALTER USER postgres WITH PASSWORD 'password';\r\n\r\n# way_2 to connect to postgresql\r\n\r\n# in the postgres client\r\nCREATE ROLE root WITH LOGIN PASSWORD 'root';\r\nALTER ROLE root CREATEDB;\r\n\r\n# connect to postgres in a terminal\r\npsql postgres\r\n\r\n# your username should be listed\r\npostgres=# \\du\r\n\r\n# let's validate it\r\npostgres=# \\q;\r\n\r\n# and then:\r\npsql -U brunoflaven postgres;\r\npsql -U root postgres;\r\n\r\n# to quit\r\npostgres=# \\q;\r\n\r\n# list all databases\r\npostgres=# \\list;\r\npostgres=# \\l;\r\n\r\n# connect to a certain database\r\npostgres=# \\c; <db name>\r\n\r\n# examples with real postgres databases\r\npostgres=# \\c postgres;\r\npostgres=# \\c mydatabase_try_postgresql;\r\npostgres=# \\c template1;\r\n\r\n# list all tables in the current database using your search_path\r\npostgres=# \\dt;\r\n\r\n\r\n# In postgres, in the console, give a complete creation tables and and insert datas for a database named \"mydatabase_try_postgresql\"\r\n\r\n\r\n# connect to the newly created database\r\n\\c mydatabase_try_postgresql\r\n\r\n# Create 'users' table\r\nCREATE TABLE users (\r\n    user_id SERIAL PRIMARY KEY,\r\n    username VARCHAR(50) NOT NULL,\r\n    email VARCHAR(100) NOT NULL\r\n);\r\n\r\n# Create 'orders' table\r\nCREATE TABLE orders (\r\n    order_id SERIAL PRIMARY KEY,\r\n    user_id INT REFERENCES users(user_id),\r\n    order_date DATE,\r\n    total_amount DECIMAL(10, 2) NOT NULL\r\n);\r\n\r\n\r\n\r\n\r\n# configure postgresql db in superset\r\n# Not working localhost or 127.0.0.1 on Mac\r\n# Working docker.for.mac.host.internal or 127.0.0.1 on Mac\r\n\r\n\r\n# select postgresql\r\n# add port 5432\r\n# add host docker.for.mac.host.internal\r\n# db_name : mydatabase_try_postgresql\r\n# user: postgres\r\n# pwd: password\r\n\r\n\r\n# createdb mydatabase_try_postgresql\r\n# dropdb mydatabase_try_postgresql\r\n<\/pre>\n<p><i>This time, for this POC, I did not install <code>mysql<\/code> and <code>mongodb<\/code> as I want to have a &#8220;quick and dirty&#8221; csv conversion into superset.<\/i><\/p>\n<p><b>Customization with <code>.env<\/code> for Superset<\/b><br \/>\nModify the .env files for environment-specific configurations and install additional Python packages by adding them to requirements-local.txt.<br \/>\nYou can use a combinaison of a docker-compose.yml file and .env file to install Superset with docker-compose.<\/p>\n<pre>\r\n# You can create some_random_base64_string using this command in shell\r\nopenssl rand -base64 42\r\n# OUTPUT: uKqlflwJGdDH\/+NpwuRhJh8mZrNsTGu45OMT7akZhGhaBlOqkkOR0xMP\r\n\r\n# in the mac terminal define the SUPERSET_SECRET_KEY\r\nexport SUPERSET_SECRET_KEY=\"uKqlflwJGdDH\/+NpwuRhJh8mZrNsTGu45OMT7akZhGhaBlOqkkOR0xMP\"\r\n\r\n<\/pre>\n<pre>\r\n# Lists containers (and tells you which images they are spun from)\r\ndocker ps -a                \r\n\r\n# Lists images \r\ndocker images               \r\n\r\n# Removes a stopped container\r\ndocker rm <container_id>    \r\n\r\n# Forces the removal of a running container (uses SIGKILL)\r\ndocker rm -f <container_id> \r\n\r\n# Removes an image\r\n# Will fail if there is a running instance of that image i.e. container\r\ndocker rmi <image_id>       \r\n\r\n\r\n# Forces removal of image even if it is referenced in multiple repositories, \r\n# i.e. same image id given multiple names\/tags \r\n# Will still fail if there is a docker container referencing image\r\ndocker rmi -f <image_id>    \r\n\r\n\r\n# command for docker\r\ndocker info\r\ndocker container prune -a\r\ndocker image prune\r\ndocker volume prune\r\ndocker network prune\r\ndocker system prune\r\ndocker system prune -a\r\n<\/pre>\n<h2>3. Collecting data: Using kafka, a corner stone<\/H2><br \/>\nApache Kafka is a distributed streaming platform that is widely used for building real-time data pipelines and streaming applications. In the context of an analytics application, Kafka plays a crucial role in handling the flow of data between different components of the application. It provides a scalable, fault-tolerant, and high-throughput messaging system that allows seamless communication between various modules of the analytics application.<\/p>\n<p>Here are some key purposes of Kafka within an analytics application:<\/p>\n<ol>\n<li><b>Data Ingestion<\/b>: Kafka acts as a central hub for ingesting data from various sources such as databases, logs, sensors, and other systems. It enables the application to handle large volumes of incoming data in a scalable and efficient manner.<\/li>\n<li><b>Event Streaming<\/b>: Kafka allows the streaming of events in real-time. This is beneficial for analytics applications that require continuous processing of data, enabling real-time insights and analytics.<\/li>\n<li><b>Decoupling of Components<\/b>: Kafka helps in decoupling different components of the analytics application. Producers can publish data to Kafka topics without worrying about who will consume it, and consumers can subscribe to the topics they are interested in.<\/li>\n<li><b>Fault Tolerance and Durability<\/b>: Kafka ensures fault tolerance by replicating data across multiple nodes. This makes it a reliable and durable solution, ensuring that data is not lost in case of failures.<\/li>\n<\/ol>\n<p><i>Source: <a href=\"https:\/\/kafka.apache.org\/\" target=\"_blank\" rel=\"noopener\">https:\/\/kafka.apache.org\/<\/a><\/i><\/p>\n<p><b>We are going to take the most straightforward way on mac, meaning using homebrew like we did previously for database. The commands will almost the same as we will use Homebrew.<\/b><\/p>\n<p>Again, if you need to install homebrew, type in the console, the following command.<\/p>\n<pre>\r\n\/bin\/bash -c \"$(curl -fsSL https:\/\/raw.githubusercontent.com\/Homebrew\/install\/HEAD\/install.sh)\"\r\n<\/pre>\n<p><b>To install kafka with Homebrew<\/b><\/p>\n<pre>\r\nbrew install kafka\r\n<\/pre>\n<p><b>To list the services from Homebrew<\/b><\/p>\n<pre>\r\nbrew services list\r\n<\/pre>\n<p><b>If you&#8217;ve installed Kafka and Zookeeper using Homebrew on your macOS system, you can use the following commands to interact with Kafka and gain an understanding of its general principles.<\/b><\/p>\n<p><b>1. Start Zookeeper:<\/b><br \/>\nZookeeper is a prerequisite for Kafka, and it manages distributed configurations and synchronization between nodes. Open a terminal and start Zookeeper:<\/p>\n<pre>\r\nbrew services start zookeeper\r\n<\/pre>\n<p><b>2. Start Kafka Server:<\/b><\/p>\n<p>Now, start the Kafka server using Homebrew:<\/p>\n<pre>\r\nbrew services start kafka\r\n<\/pre>\n<p>This command will start the Kafka server as a background service.<\/p>\n<p><b>3. Create a Topic:<\/b><\/p>\n<p>Kafka organizes data into topics. Create a Kafka topic to publish and subscribe messages:<\/p>\n<pre>\r\nkafka-topics --create --topic brunotopic1 --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1\r\n<\/pre>\n<p>Replace `brunotopic1` with the desired topic name.<\/p>\n<p><b>4. List Topics:<\/b><\/p>\n<p>List the existing Kafka topics:<\/p>\n<pre>\r\nkafka-topics --list --bootstrap-server localhost:9092\r\n<\/pre>\n<p><b>5. Produce Messages:<\/b><\/p>\n<p>Produce some messages to the topic:<\/p>\n<pre>\r\nkafka-console-producer --topic brunotopic1 --bootstrap-server localhost:9092\r\n<\/pre>\n<p>This command opens a console where you can type messages. Press `Ctrl + D` to exit.<\/p>\n<p><b>6. Consume Messages:<\/b><\/p>\n<p>Open a new terminal and consume messages from the topic:<\/p>\n<pre>\r\nkafka-console-consumer --topic brunotopic1 --bootstrap-server localhost:9092 --from-beginning\r\n<\/pre>\n<p>This command subscribes to the topic and prints incoming messages.<\/p>\n<p><b>7. Describe a Topic:<\/b><\/p>\n<p>Describe the properties of a Kafka topic:<\/p>\n<pre>\r\nkafka-topics --describe --topic brunotopic1 --bootstrap-server localhost:9092\r\n<\/pre>\n<p><b>8. Kafka Commands Documentation:<\/b><\/p>\n<p>Explore additional Kafka commands and options by checking the official documentation:<\/p>\n<pre>\r\nkafka-topics --help\r\nkafka-console-producer --help\r\nkafka-console-consumer --help\r\n<\/pre>\n<p><b>9. Stop Kafka:<\/b><\/p>\n<p>When you&#8217;re done, you can stop the Kafka server:<\/p>\n<pre>\r\nbrew services stop kafka\r\nbrew services stop zookeeper\r\n<\/pre>\n<p>This will stop the Kafka server running as a background service.<\/p>\n<p>These commands provide a basic overview of Kafka&#8217;s functionalities. You can experiment further and refer to the [official documentation](https:\/\/kafka.apache.org\/documentation\/) for more in-depth understanding and configuration options.<\/p>\n<p><b>Using faststream<\/b><\/p>\n<p>To go further, you can leverage on <b>FastStream<\/b>. A kind of <b>FastAPI<\/b> for Kafka. Indeed, FastStream simplifies the process of writing producers and consumers for message queues, handling all the parsing, networking and documentation generation automatically.<\/p>\n<p><i>Source: <a href=\"https:\/\/faststream.airt.ai\/latest\/faststream\/\" target=\"_blank\" rel=\"noopener\">https:\/\/faststream.airt.ai\/latest\/faststream\/<\/a><\/i><\/p>\n<p><H2>More infos<\/H2><br \/>\n<H3>Superset<\/H3><\/p>\n<ul>\n<li>Welcome | Superset<br \/><a href=\"https:\/\/superset.apache.org\/\" target=\"_blank\" rel=\"noopener\">https:\/\/superset.apache.org\/<\/a><\/li>\n<li>Apache Superset Tutorial \u00b7 Start Data Engineering<br \/><a href=\"https:\/\/www.startdataengineering.com\/post\/apache-superset-tutorial\/\" target=\"_blank\" rel=\"noopener\">https:\/\/www.startdataengineering.com\/post\/apache-superset-tutorial\/<\/a><\/li>\n<li>Introduction | Superset<br \/><a href=\"https:\/\/superset.apache.org\/docs\/intro\/\" target=\"_blank\" rel=\"noopener\">https:\/\/superset.apache.org\/docs\/intro\/<\/a><\/li>\n<li>Setting up Superset GitHub Integration: 3 Easy Methods<br \/><a href=\"https:\/\/hevodata.com\/learn\/superset-github\/#l12\" target=\"_blank\" rel=\"noopener\">https:\/\/hevodata.com\/learn\/superset-github\/#l12<\/a><\/li>\n<li>Course Bytes &#8211; YouTube<br \/><a href=\"https:\/\/www.youtube.com\/@coursebytes\" target=\"_blank\" rel=\"noopener\">https:\/\/www.youtube.com\/@coursebytes<\/a><\/li>\n<li>Preset Cloud &#8211; Modern Open Source BI Platform | Preset<br \/><a href=\"https:\/\/preset.io\/product\/\" target=\"_blank\" rel=\"noopener\">https:\/\/preset.io\/product\/<\/a><\/li>\n<li>Get started with Apache Superset and PostgreSQL\u00ae<br \/><a href=\"https:\/\/aiven.io\/blog\/get-started-with-apache-superset-and-postgresql\" target=\"_blank\" rel=\"noopener\">https:\/\/aiven.io\/blog\/get-started-with-apache-superset-and-postgresql<\/a><\/li>\n<li>Tutorial &#8211; Creating your first dashboard \u2014 Apache Superset  documentation<br \/><a href=\"https:\/\/apache-superset.readthedocs.io\/en\/0.28.1\/tutorial.html\" target=\"_blank\" rel=\"noopener\">https:\/\/apache-superset.readthedocs.io\/en\/0.28.1\/tutorial.html<\/a><\/li>\n<li>Introduction \u00e0 Apache Superset &#8211; datacorner par Benoit Cayla<br \/><a href=\"https:\/\/datacorner.fr\/introduction-a-apache-superset\/\" target=\"_blank\" rel=\"noopener\">https:\/\/datacorner.fr\/introduction-a-apache-superset\/<\/a><\/li>\n<li>Documentation Superset \u2014 Restack<br \/><a href=\"https:\/\/www.restack.io\/docs\/superset\" target=\"_blank\" rel=\"noopener\">https:\/\/www.restack.io\/docs\/superset<\/a><\/li>\n<li>GitHub &#8211; apache\/superset: Apache Superset is a Data Visualization and Data Exploration Platform<br \/><a href=\"https:\/\/github.com\/apache\/superset\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/apache\/superset<\/a><\/li>\n<li>Apache Superset Tutorial | Censius Blog<br \/><a href=\"https:\/\/censius.ai\/blogs\/apache-superset-tutorial\" target=\"_blank\" rel=\"noopener\">https:\/\/censius.ai\/blogs\/apache-superset-tutorial<\/a><\/li>\n<li>Fully managed Redash \u2014 Restack<br \/><a href=\"https:\/\/www.restack.io\/store\/redash\" target=\"_blank\" rel=\"noopener\">https:\/\/www.restack.io\/store\/redash<\/a><\/li>\n<li>Apache Superset Overview Video &#8211; YouTube<br \/><a href=\"https:\/\/www.youtube.com\/watch?v=kGfUIOK87V8\" target=\"_blank\" rel=\"noopener\">https:\/\/www.youtube.com\/watch?v=kGfUIOK87V8<\/a><\/li>\n<li>Redash vs Superset: Which data visualization tool should you select? &#8211; YouTube<br \/><a href=\"https:\/\/www.youtube.com\/watch?v=U33wA0gW01M\" target=\"_blank\" rel=\"noopener\">https:\/\/www.youtube.com\/watch?v=U33wA0gW01M<\/a><\/li>\n<li>Comment utiliser l\u2019IA pour l\u2019analyse des donn\u00e9es ? Expliqu\u00e9 avec plusieurs cas d&#8217;utilisation<br \/><a href=\"https:\/\/www.edrawsoft.com\/fr\/ai-tools-tips\/ai-for-data-analysis.html\" target=\"_blank\" rel=\"noopener\">https:\/\/www.edrawsoft.com\/fr\/ai-tools-tips\/ai-for-data-analysis.html<\/a><\/li>\n<li>403 Forbidden<br \/><a href=\"https:\/\/online.edhec.edu\/fr\/blog\/le-role-de-lia-et-du-machine-learning\/\" target=\"_blank\" rel=\"noopener\">https:\/\/online.edhec.edu\/fr\/blog\/le-role-de-lia-et-du-machine-learning\/<\/a><\/li>\n<li>Attention Required! | Cloudflare<br \/><a href=\"https:\/\/geekflare.com\/fr\/ai-data-analysis-tools\/\" target=\"_blank\" rel=\"noopener\">https:\/\/geekflare.com\/fr\/ai-data-analysis-tools\/<\/a><\/li>\n<li>6 Best AI Tools for Data Analysts (January 2024) &#8211; Unite.AI<br \/><a href=\"https:\/\/www.unite.ai\/ai-tools-data-analysts\/\" target=\"_blank\" rel=\"noopener\">https:\/\/www.unite.ai\/ai-tools-data-analysts\/<\/a><\/li>\n<li>AutoML and AutoAI &#8211; IBM Watson Studio<br \/><a href=\"https:\/\/www.ibm.com\/products\/watson-studio\/autoai\" target=\"_blank\" rel=\"noopener\">https:\/\/www.ibm.com\/products\/watson-studio\/autoai<\/a><\/li>\n<li>How to Perform Data Analysis in Python Using the OpenAI API \u2014 SitePoint<br \/><a href=\"https:\/\/www.sitepoint.com\/openai-api-python-data-analysis\/\" target=\"_blank\" rel=\"noopener\">https:\/\/www.sitepoint.com\/openai-api-python-data-analysis\/<\/a><\/li>\n<li>GitHub &#8211; Apress\/python-data-analytics-2e: Source Code for &#8216;Python Data Analytics, 2nd Edition&#8217; by Fabio Nelli<br \/><a href=\"https:\/\/github.com\/Apress\/python-data-analytics-2e\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/Apress\/python-data-analytics-2e<\/a><\/li>\n<li>Python for Data Analysis, 3E<br \/><a href=\"https:\/\/wesmckinney.com\/book\/\" target=\"_blank\" rel=\"noopener\">https:\/\/wesmckinney.com\/book\/<\/a><\/li>\n<li>100+ AI Use Cases &#038; Applications: In-Depth Guide for 2024<br \/><a href=\"https:\/\/research.aimultiple.com\/ai-usecases\/#ai-use-cases-for-marketing\" target=\"_blank\" rel=\"noopener\">https:\/\/research.aimultiple.com\/ai-usecases\/#ai-use-cases-for-marketing<\/a><\/li>\n<li>Devinterview.io \u2013 Ace your next tech interview with confidence in 2024.<br \/><a href=\"https:\/\/devinterview.io\/\" target=\"_blank\" rel=\"noopener\">https:\/\/devinterview.io\/<\/a><\/li>\n<li>GitHub &#8211; DerekKane\/Use-Cases-Data-Science: A list of working examples of Data Science Use Cases and Applications by Industry<br \/><a href=\"https:\/\/github.com\/DerekKane\/Use-Cases-Data-Science\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/DerekKane\/Use-Cases-Data-Science<\/a><\/li>\n<li>Fast Open-Source OLAP DBMS &#8211; ClickHouse<br \/><a href=\"https:\/\/clickhouse.com\/\" target=\"_blank\" rel=\"noopener\">https:\/\/clickhouse.com\/<\/a><\/li>\n<li>GitHub &#8211; ClickHouse\/ClickHouse: ClickHouse\u00ae is a free analytics DBMS for big data<br \/><a href=\"https:\/\/github.com\/ClickHouse\/ClickHouse\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/ClickHouse\/ClickHouse<\/a><\/li>\n<li>GitHub &#8211; apache\/zeppelin: Web-based notebook that enables data-driven, interactive data analytics and collaborative documents with SQL, Scala and more.<br \/><a href=\"https:\/\/github.com\/apache\/zeppelin\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/apache\/zeppelin<\/a><\/li>\n<li>GitHub &#8211; datafuselabs\/databend: Modern alternative to Snowflake. Cost-effective and simple for massive-scale analytics. Cloud: https:\/\/databend.com<br \/><a href=\"https:\/\/github.com\/datafuselabs\/databend\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/datafuselabs\/databend<\/a><\/li>\n<li>GitHub &#8211; apache\/spark: Apache Spark &#8211; A unified analytics engine for large-scale data processing<br \/><a href=\"https:\/\/github.com\/apache\/spark\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/apache\/spark<\/a><\/li>\n<li>GitHub &#8211; metabase\/metabase: The simplest, fastest way to get business intelligence and analytics to everyone in your company :yum:<br \/><a href=\"https:\/\/github.com\/metabase\/metabase\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/metabase\/metabase<\/a><\/li>\n<li>GitHub &#8211; getredash\/redash: Make Your Company Data Driven. Connect to any data source, easily visualize, dashboard and share your data.<br \/><a href=\"https:\/\/github.com\/getredash\/redash\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/getredash\/redash<\/a><\/li>\n<li>GitHub &#8211; microsoft\/ML-For-Beginners: 12 weeks, 26 lessons, 52 quizzes, classic Machine Learning for all<br \/><a href=\"https:\/\/github.com\/microsoft\/ML-For-Beginners\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/microsoft\/ML-For-Beginners<\/a><\/li>\n<li>Fast Open-Source OLAP DBMS &#8211; ClickHouse<br \/><a href=\"https:\/\/clickhouse.com\/\" target=\"_blank\" rel=\"noopener\">https:\/\/clickhouse.com\/<\/a><\/li>\n<li>How to setup PostgreSQL on MacOS<br \/><a href=\"https:\/\/www.robinwieruch.de\/postgres-sql-macos-setup\/\" target=\"_blank\" rel=\"noopener\">https:\/\/www.robinwieruch.de\/postgres-sql-macos-setup\/<\/a><\/li>\n<li>Apache Superset on Mac M1 Guide \u2014 Restack<br \/><a href=\"https:\/\/www.restack.io\/docs\/superset-knowledge-apache-superset-mac-m1-guide\" target=\"_blank\" rel=\"noopener\">https:\/\/www.restack.io\/docs\/superset-knowledge-apache-superset-mac-m1-guide<\/a><\/li>\n<li>Advanced Apache Superset for Data Engineers \u2014 Restack<br \/><a href=\"https:\/\/www.restack.io\/docs\/superset-advanced-apache-superset-data-engineers\" target=\"_blank\" rel=\"noopener\">https:\/\/www.restack.io\/docs\/superset-advanced-apache-superset-data-engineers<\/a><\/li>\n<li>GitHub &#8211; kkiaune\/emails-classification: Emails classification template using python. Technology stack: docker-compose, jupyter notebooks, fastapi, airflow, posgreSQL, superset, minio, portainer, pgAdmin<br \/><a href=\"https:\/\/github.com\/kkiaune\/emails-classification\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/kkiaune\/emails-classification<\/a><\/li>\n<li>GitHub &#8211; JDiego199\/superset-docker-compose<br \/><a href=\"https:\/\/github.com\/JDiego199\/superset-docker-compose\/\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/JDiego199\/superset-docker-compose\/<\/a><\/li>\n<li>GitHub &#8211; mauricioobgo\/StreamingProject: This Docker Compose project establishes a data pipeline with Apache Spark, Kafka, Cassandra, MySQL, and Superset. Engineered for real-time processing of streaming data, it stores results in distributed databases and offers visualization through Superset dashboards.<br \/><a href=\"https:\/\/github.com\/mauricioobgo\/StreamingProject\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/mauricioobgo\/StreamingProject<\/a><\/li>\n<li>GitHub &#8211; insight-infrastructure\/superset-docker-compose: Superset deployed with docker-compose and features<br \/><a href=\"https:\/\/github.com\/insight-infrastructure\/superset-docker-compose\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/insight-infrastructure\/superset-docker-compose<\/a><\/li>\n<li>Supercharging Apache Superset | by Airbnb | The Airbnb Tech Blog<br \/><a href=\"https:\/\/medium.com\/airbnb-engineering\/supercharging-apache-superset-b1a2393278bd\" target=\"_blank\" rel=\"noopener\">https:\/\/medium.com\/airbnb-engineering\/supercharging-apache-superset-b1a2393278bd<\/a><\/li>\n<li>Running Apache Superset at Scale. A set of recommendations and starting\u2026 | by Mahdi Karabiben | Towards Data Science<br \/><a href=\"https:\/\/towardsdatascience.com\/running-apache-superset-at-scale-1539e3945093\" target=\"_blank\" rel=\"noopener\">https:\/\/towardsdatascience.com\/running-apache-superset-at-scale-1539e3945093<\/a><\/li>\n<li>How Airbnb Achieved Metric Consistency at Scale | by Robert Chang | The Airbnb Tech Blog | Medium<br \/><a href=\"https:\/\/medium.com\/airbnb-engineering\/how-airbnb-achieved-metric-consistency-at-scale-f23cc53dea70\" target=\"_blank\" rel=\"noopener\">https:\/\/medium.com\/airbnb-engineering\/how-airbnb-achieved-metric-consistency-at-scale-f23cc53dea70<\/a><\/li>\n<li>How Airbnb Achieved Metric Consistency at Scale | by Robert Chang | The Airbnb Tech Blog | Medium<br \/><a href=\"https:\/\/medium.com\/airbnb-engineering\/how-airbnb-achieved-metric-consistency-at-scale-f23cc53dea70\" target=\"_blank\" rel=\"noopener\">https:\/\/medium.com\/airbnb-engineering\/how-airbnb-achieved-metric-consistency-at-scale-f23cc53dea70<\/a><\/li>\n<li>Pricing | Preset<br \/><a href=\"https:\/\/preset.io\/pricing\/\" target=\"_blank\" rel=\"noopener\">https:\/\/preset.io\/pricing\/<\/a><\/li>\n<li>Connecting Your Data<br \/><a href=\"https:\/\/docs.preset.io\/v1\/docs\/connecting-your-data\" target=\"_blank\" rel=\"noopener\">https:\/\/docs.preset.io\/v1\/docs\/connecting-your-data<\/a><\/li>\n<li>How to build a real-time analytics platform using Kafka, ksqlDB and ClickHouse ? | by Florian Hussonnois | StreamThoughts | Medium<br \/><a href=\"https:\/\/medium.com\/streamthoughts\/how-to-build-a-real-time-analytical-platform-using-kafka-ksqldb-and-clickhouse-bfabd65d05e4\" target=\"_blank\" rel=\"noopener\">https:\/\/medium.com\/streamthoughts\/how-to-build-a-real-time-analytical-platform-using-kafka-ksqldb-and-clickhouse-bfabd65d05e4<\/a><\/li>\n<li>Build a Real-Time Event Streaming Pipeline with Kafka, BigQuery &#038; Looker Studio | by Tobi Sam | Towards Data Science<br \/><a href=\"https:\/\/towardsdatascience.com\/real-time-event-streaming-with-kafka-bigquery-69c3baebb51e\" target=\"_blank\" rel=\"noopener\">https:\/\/towardsdatascience.com\/real-time-event-streaming-with-kafka-bigquery-69c3baebb51e<\/a><\/li>\n<li>Stream data with open source Kafka by Aiven analyze with BigQuery | Google Cloud Blog<br \/><a href=\"https:\/\/cloud.google.com\/blog\/products\/data-analytics\/stream-data-with-open-source-kafka-by-aiven-analyze-with-bigquery\" target=\"_blank\" rel=\"noopener\">https:\/\/cloud.google.com\/blog\/products\/data-analytics\/stream-data-with-open-source-kafka-by-aiven-analyze-with-bigquery<\/a><\/li>\n<li>Restack &#8211; YouTube<br \/><a href=\"https:\/\/www.youtube.com\/@Restackio\" target=\"_blank\" rel=\"noopener\">https:\/\/www.youtube.com\/@Restackio<\/a><\/li>\n<li>Better Data Science &#8211; YouTube<br \/><a href=\"https:\/\/www.youtube.com\/@BetterDataScience\/videos\" target=\"_blank\" rel=\"noopener\">https:\/\/www.youtube.com\/@BetterDataScience\/videos<\/a><\/li>\n<li>Overview of Real-Time Analytics &#8211; Microsoft Fabric | Microsoft Learn<br \/><a href=\"https:\/\/learn.microsoft.com\/en-us\/fabric\/real-time-analytics\/overview#what-makes-real-time-analytics-unique\" target=\"_blank\" rel=\"noopener\">https:\/\/learn.microsoft.com\/en-us\/fabric\/real-time-analytics\/overview#what-makes-real-time-analytics-unique<\/a><\/li>\n<li>Build a real-time analytics pipeline in less time than your morning bus ride<br \/><a href=\"https:\/\/aiven.io\/blog\/build-a-real-time-analytics-pipeline\" target=\"_blank\" rel=\"noopener\">https:\/\/aiven.io\/blog\/build-a-real-time-analytics-pipeline<\/a><\/li>\n<li>What is real-time analytics? &#8211; DEV Community<br \/><a href=\"https:\/\/dev.to\/tinybirdco\/what-is-real-time-analytics-5ah3\" target=\"_blank\" rel=\"noopener\">https:\/\/dev.to\/tinybirdco\/what-is-real-time-analytics-5ah3<\/a><\/li>\n<li>Building real-time analytics into your next project &#8211; DEV Community<br \/><a href=\"https:\/\/dev.to\/tinybirdco\/building-real-time-analytics-into-your-next-project-3b6n\" target=\"_blank\" rel=\"noopener\">https:\/\/dev.to\/tinybirdco\/building-real-time-analytics-into-your-next-project-3b6n<\/a><\/li>\n<li>Real-time analytics with stream processing and OLAP | CNCF<br \/><a href=\"https:\/\/www.cncf.io\/blog\/2023\/08\/08\/real-time-analytics-with-stream-processing-and-olap\/\" target=\"_blank\" rel=\"noopener\">https:\/\/www.cncf.io\/blog\/2023\/08\/08\/real-time-analytics-with-stream-processing-and-olap\/<\/a><\/li>\n<li>Real-time analytics on big data architecture &#8211; Azure Solution Ideas | Microsoft Learn<br \/><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/architecture\/solution-ideas\/articles\/real-time-analytics\" target=\"_blank\" rel=\"noopener\">https:\/\/learn.microsoft.com\/en-us\/azure\/architecture\/solution-ideas\/articles\/real-time-analytics<\/a><\/li>\n<li>Real-time Databases: What developers need to know<br \/><a href=\"https:\/\/www.tinybird.co\/blog-posts\/real-time-databases-what-developers-need-to-know\" target=\"_blank\" rel=\"noopener\">https:\/\/www.tinybird.co\/blog-posts\/real-time-databases-what-developers-need-to-know<\/a><\/li>\n<li>Real time analytics: Airflow + Kafka + Druid + Superset &#8211; [Eng] | Duy Nguyen<br \/><a href=\"https:\/\/duynguyenngoc.com\/posts\/real-time-analytics-airflow-kafka-druid-superset\/\" target=\"_blank\" rel=\"noopener\">https:\/\/duynguyenngoc.com\/posts\/real-time-analytics-airflow-kafka-druid-superset\/<\/a><\/li>\n<li>Realtime data streaming with Apache Kafka, Apache Pinot, Apache Druid and Apache Superset | by Bruno Cardoso Farias | Medium<br \/><a href=\"https:\/\/medium.com\/@emergeit\/realtime-data-streaming-with-apache-kafka-apache-pinot-apache-druid-and-apache-superset-e67161eb9666\" target=\"_blank\" rel=\"noopener\">https:\/\/medium.com\/@emergeit\/realtime-data-streaming-with-apache-kafka-apache-pinot-apache-druid-and-apache-superset-e67161eb9666<\/a><\/li>\n<li>Unlock Advanced Data Visualization: The Complete Guide to Installing and Using Apache Superset on Linux | by Rathish Kumar B | Level Up Coding<br \/><a href=\"https:\/\/levelup.gitconnected.com\/unlock-advanced-data-visualization-the-complete-guide-to-installing-and-using-apache-superset-on-afecb3c63889\" target=\"_blank\" rel=\"noopener\">https:\/\/levelup.gitconnected.com\/unlock-advanced-data-visualization-the-complete-guide-to-installing-and-using-apache-superset-on-afecb3c63889<\/a><\/li>\n<li>Kafka in 100 Seconds &#8211; YouTube<br \/><a href=\"https:\/\/www.youtube.com\/watch?v=uvb00oaa3k8\" target=\"_blank\" rel=\"noopener\">https:\/\/www.youtube.com\/watch?v=uvb00oaa3k8<\/a><\/li>\n<li>Apache Superset: Installing locally is easy using the makefile &#8211; DEV Community<br \/><a href=\"https:\/\/dev.to\/lyndsiwilliams\/apache-superset-installing-locally-is-easy-using-the-makefile-4ofi\" target=\"_blank\" rel=\"noopener\">https:\/\/dev.to\/lyndsiwilliams\/apache-superset-installing-locally-is-easy-using-the-makefile-4ofi<\/a><\/li>\n<li>Setting up a local Apache Kafka instance for testing &#8211; Sahan Serasinghe &#8211; Engineering Blog<br \/><a href=\"https:\/\/sahansera.dev\/setting-up-kafka-locally-for-testing\/\" target=\"_blank\" rel=\"noopener\">https:\/\/sahansera.dev\/setting-up-kafka-locally-for-testing\/<\/a><\/li>\n<li>Postico 2<br \/><a href=\"https:\/\/eggerapps.at\/postico2\/\" target=\"_blank\" rel=\"noopener\">https:\/\/eggerapps.at\/postico2\/<\/a><\/li>\n<li>DBeaver Community | Free Universal Database Tool<br \/><a href=\"https:\/\/dbeaver.io\/\" target=\"_blank\" rel=\"noopener\">https:\/\/dbeaver.io\/<\/a><\/li>\n<li>Manage MySQL, MongoDB and PostgreSQL using Homebrew Services<br \/><a href=\"https:\/\/www.chrisjmendez.com\/2017\/02\/04\/homebrew-services\/\" target=\"_blank\" rel=\"noopener\">https:\/\/www.chrisjmendez.com\/2017\/02\/04\/homebrew-services\/<\/a><\/li>\n<li>Install MongoDB, MySQL, and Postgres using Homebrew<br \/><a href=\"https:\/\/www.chrisjmendez.com\/2016\/05\/09\/easy-mongodb-and-mysql-management-on-a-mac\/\" target=\"_blank\" rel=\"noopener\">https:\/\/www.chrisjmendez.com\/2016\/05\/09\/easy-mongodb-and-mysql-management-on-a-mac\/<\/a><\/li>\n<li>GitHub &#8211; datablist\/sample-csv-files<br \/><a href=\"https:\/\/github.com\/datablist\/sample-csv-files\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/datablist\/sample-csv-files<\/a><\/li>\n<li>Tweets Sample | Kaggle<br \/><a href=\"https:\/\/www.kaggle.com\/datasets\/ahmedshahriarsakib\/tweet-sample\" target=\"_blank\" rel=\"noopener\">https:\/\/www.kaggle.com\/datasets\/ahmedshahriarsakib\/tweet-sample<\/a><\/li>\n<li>Expanding Visibility With Apache Kafka &#8211; Salesforce Engineering Blog<br \/><a href=\"https:\/\/engineering.salesforce.com\/expanding-visibility-with-apache-kafka-e305b12c4aba\/\" target=\"_blank\" rel=\"noopener\">https:\/\/engineering.salesforce.com\/expanding-visibility-with-apache-kafka-e305b12c4aba\/<\/a><\/li>\n<li>How to setup Apache SuperSet &#8211; YouTube<br \/><a href=\"https:\/\/www.youtube.com\/watch?v=08jK2FbPMNI\" target=\"_blank\" rel=\"noopener\">https:\/\/www.youtube.com\/watch?v=08jK2FbPMNI<\/a><\/li>\n<\/ul>\n<p><H3>Kafka<\/H3><\/p>\n<ul>\n<li>Building an Order Delivery Analytics Application With FastAPI, Kafka, Apache Pinot, and Dash, Part 1 | by Valerio Uberti | Better Programming<br \/><a href=\"https:\/\/betterprogramming.pub\/building-an-order-delivery-analytics-application-with-fastapi-kafka-apache-pinot-and-dash-part-ca276a3ee631\" target=\"_blank\" rel=\"noopener\">https:\/\/betterprogramming.pub\/building-an-order-delivery-analytics-application-with-fastapi-kafka-apache-pinot-and-dash-part-ca276a3ee631<\/a><\/li>\n<li>Building an Order Delivery Analytics Application with FastAPI, Kafka, Apache Pinot, and Dash, Part 2 | by Valerio Uberti | Better Programming<br \/><a href=\"https:\/\/betterprogramming.pub\/building-an-order-delivery-analytics-application-with-fastapi-kafka-apache-pinot-and-dash-part-f98202296d64\" target=\"_blank\" rel=\"noopener\">https:\/\/betterprogramming.pub\/building-an-order-delivery-analytics-application-with-fastapi-kafka-apache-pinot-and-dash-part-f98202296d64<\/a><\/li>\n<li>Generating production-level streaming microservices using AI &#8211; DEV Community<br \/><a href=\"https:\/\/dev.to\/airtai\/generating-production-level-streaming-microservices-using-ai-41ji\" target=\"_blank\" rel=\"noopener\">https:\/\/dev.to\/airtai\/generating-production-level-streaming-microservices-using-ai-41ji<\/a><\/li>\n<li>An asynchronous Consumer and Producer API for Kafka with FastAPI in Python &#8211; Home<br \/><a href=\"https:\/\/vinybrasil.github.io\/portfolio\/kafkafastapiasync\/\" target=\"_blank\" rel=\"noopener\">https:\/\/vinybrasil.github.io\/portfolio\/kafkafastapiasync\/<\/a><\/li>\n<li>GitHub &#8211; pedrodeoliveira\/fastapi-kafka-consumer: A Python RESTful API using FastAPI with a Kafka Consumer<br \/><a href=\"https:\/\/github.com\/pedrodeoliveira\/fastapi-kafka-consumer\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/pedrodeoliveira\/fastapi-kafka-consumer<\/a><\/li>\n<li>FastStream: Python&#8217;s framework for Efficient Message Queue Handling &#8211; DEV Community<br \/><a href=\"https:\/\/dev.to\/airtai\/faststream-pythons-framework-for-efficient-message-queue-handling-3pd2\" target=\"_blank\" rel=\"noopener\">https:\/\/dev.to\/airtai\/faststream-pythons-framework-for-efficient-message-queue-handling-3pd2<\/a><\/li>\n<li>Getting Started &#8211; FastStream<br \/><a href=\"https:\/\/faststream.airt.ai\/latest\/getting-started\/\" target=\"_blank\" rel=\"noopener\">https:\/\/faststream.airt.ai\/latest\/getting-started\/<\/a><\/li>\n<li>Streamlining Asynchronous Services with FastStream | NATS blog<br \/><a href=\"https:\/\/nats.io\/blog\/nats-supported-by-faststream\/\" target=\"_blank\" rel=\"noopener\">https:\/\/nats.io\/blog\/nats-supported-by-faststream\/<\/a><\/li>\n<li>Kafka &#8211; DEV Community<br \/><a href=\"https:\/\/dev.to\/t\/kafka\" target=\"_blank\" rel=\"noopener\">https:\/\/dev.to\/t\/kafka<\/a><\/li>\n<li>Demystifying Apache Kafka: An exploratory journey for newcomers &#8211; DEV Community<br \/><a href=\"https:\/\/dev.to\/ladmerc\/demystifying-apache-kafka-an-exploratory-journey-for-newcomers-18k9\" target=\"_blank\" rel=\"noopener\">https:\/\/dev.to\/ladmerc\/demystifying-apache-kafka-an-exploratory-journey-for-newcomers-18k9<\/a><\/li>\n<li>Install Apache Kafka on macOS using Homebrew &#8211; DEV Community<br \/><a href=\"https:\/\/dev.to\/andremare\/install-apache-kafka-on-macos-using-homebrew-5gno\" target=\"_blank\" rel=\"noopener\">https:\/\/dev.to\/andremare\/install-apache-kafka-on-macos-using-homebrew-5gno<\/a><\/li>\n<li>FastStream: Python&#8217;s framework for Efficient Message Queue Handling &#8211; DEV Community<br \/><a href=\"https:\/\/dev.to\/airtai\/faststream-pythons-framework-for-efficient-message-queue-handling-3pd2\" target=\"_blank\" rel=\"noopener\">https:\/\/dev.to\/airtai\/faststream-pythons-framework-for-efficient-message-queue-handling-3pd2<\/a><\/li>\n<li>GitHub &#8211; Aiven-Labs\/python-fake-data-producer-for-apache-kafka: The Python fake data producer for Apache Kafka\u00ae  is a complete demo app allowing you to quickly produce JSON fake streaming datasets and push it to an Apache Kafka topic.<br \/><a href=\"https:\/\/github.com\/Aiven-Labs\/python-fake-data-producer-for-apache-kafka\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/Aiven-Labs\/python-fake-data-producer-for-apache-kafka<\/a><\/li>\n<li>Getting started with Apache Kafka using Python &#8211; DEV Community<br \/><a href=\"https:\/\/dev.to\/rubnsbarbosa\/getting-started-with-apache-kafka-using-python-36ko\" target=\"_blank\" rel=\"noopener\">https:\/\/dev.to\/rubnsbarbosa\/getting-started-with-apache-kafka-using-python-36ko<\/a><\/li>\n<li>How to Start Using Apache Kafka in Python<br \/><a href=\"https:\/\/kafkaide.com\/learn\/how-to-start-using-apache-kafka-in-python\/\" target=\"_blank\" rel=\"noopener\">https:\/\/kafkaide.com\/learn\/how-to-start-using-apache-kafka-in-python\/<\/a><\/li>\n<li>Installing and running Apache Kafka on MacOS with Apple Silicon | by Taapas Agrawal | Medium<br \/><a href=\"https:\/\/medium.com\/@taapasagrawal\/installing-and-running-apache-kafka-on-macos-with-m1-processor-5238dda81d51\" target=\"_blank\" rel=\"noopener\">https:\/\/medium.com\/@taapasagrawal\/installing-and-running-apache-kafka-on-macos-with-m1-processor-5238dda81d51<\/a><\/li>\n<li>GitHub &#8211; BenasB\/kafka-faker: User friendly and convenient Apache Kafka JSON message faking<br \/><a href=\"https:\/\/github.com\/BenasB\/kafka-faker\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/BenasB\/kafka-faker<\/a><\/li>\n<li>Kickstart your Kafka with Faker Data &#8211; Speaker Deck<br \/><a href=\"https:\/\/speakerdeck.com\/ftisiot\/kickstart-your-kafka-with-faker-data\" target=\"_blank\" rel=\"noopener\">https:\/\/speakerdeck.com\/ftisiot\/kickstart-your-kafka-with-faker-data<\/a><\/li>\n<li>Intro to Kafka using Docker and Python &#8211; DEV Community<br \/><a href=\"https:\/\/dev.to\/boyu1997\/intro-to-kafka-4hn2\" target=\"_blank\" rel=\"noopener\">https:\/\/dev.to\/boyu1997\/intro-to-kafka-4hn2<\/a><\/li>\n<\/ul>\n",
            "protected": false
        },
        "excerpt": {
            "rendered": "<p>I changed the nature of my personal sprint objective, moving away slightly from AI concerns to reconnect with more general considerations about Data and its&hellip; <\/p>\n<p class=\"text-center\"><a href=\"https:\/\/flaven.fr\/2024\/01\/navigating-the-data-landscape-exploring-key-elements-of-superset-and-kafka-for-a-real-time-analytics-platform\/\" class=\"more-link\">Continue reading &rarr; <span class=\"screen-reader-text\">Navigating the Data Landscape: Exploring Key Elements of Superset and Kafka for a Real-Time Analytics Platform<\/span><\/a><\/p>\n",
            "protected": false
        },
        "author": 1
    },
    {
        "id": 12727,
        "link": "https:\/\/flaven.fr\/2024\/01\/a-small-guide-to-harnessing-the-power-of-open-interpreter-and-unlocking-productivity-with-a-chatgpt-like-terminal-interface\/",
        "title": {
            "rendered": "A small Guide to Harnessing the Power of Open Interpreter and Unlocking Productivity with a ChatGPT-Like Terminal Interface"
        },
        "content": {
            "rendered": "<p>I am still digging on what can ease LLM querying in a confidential and secure way and at the same time, I am collecting stuff for what I have called personally and pompously the <code>PAPE<\/code> (Prompt Academy Project E-learning).  The PAPE is still in still in WIP. But, at the same time, I found plenty of tools launched almost each week. These tools reshape constantly the world of AI daily at a breakneck pace and in unprecedented proportions that makes the very phenomenon difficult to follow. Here is a concise list of my last investigation!<\/p>\n<p><b>For this post, you can find all files for each project on my GitHub account. See <a href=\"https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ia_open_interpreter\" target=\"_blank\" rel=\"noopener noreferrer\">https:\/\/github.com\/bflaven\/ia_usages\/tree\/main\/ia_open_interpreter<\/a><\/b><\/p>\n<h2>Using open-interpreter<\/h2>\n<p>By using interpreter, you are about to unleash the power of ChatGPT on your computer&#8230; Nice baseline. Their motto is &#8220;Anyone can code&#8221; like a kind of geek version of the &#8220;Anyone can cook&#8221; from Gusteau in Ratatouille.<\/p>\n<p>Basically, you can have two usage&#8217;s strategies towards open-interpreter:<\/p>\n<ol>\n<li>You can harness ChatGPT to run code on your computer to complete some tedious tasks for example: massive file renaming,<br \/>\n  extract content from a bunch of pdfs and make a summary&#8230;etc One for all, every task that you have already delegate to ChatGPT exception made that it is now taking control of your computer! <b>CAUTION: it requires a ChatGPT paid license and it will increase your monthly bill! We don&#8217;t get anything for nothing<\/b><\/li>\n<li>If you are thrifty and patient, with the help of interpreter combined with LM Studio, you can even take advantages of local LLMs such as Mistral, Orca, Codellama, Llama2&#8230; Every LLM available on huggingface.co. <b>It does no cost anything, it is more secure but is slow!<\/b><\/li>\n<\/ol>\n<p>You can have a look at the official website: <a href=\"https:\/\/openinterpreter.com\/\" target=\"_blank\" rel=\"noopener\">https:\/\/openinterpreter.com\/<\/a> or check the GitHub <a href=\"https:\/\/github.com\/KillianLucas\/open-interpreter\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/KillianLucas\/open-interpreter<\/a>.<\/p>\n<p>If you are using Anaconda, you can create a specific environment e.g &#8220;open_interpreter&#8221; or use the default one aka &#8220;base&#8221;. Up to you.<\/p>\n<p><b>Both in base or in a specific environment, it requires a paid API Key from ChatGPT e.g <code>sk-XXX-jkhjkhjkhjkh-FAKE-jkhjhXXX454423FCFG-FAKE-jk<\/code><\/b><br \/>\n<img loading=\"lazy\" decoding=\"async\" class=\"aligncenter lazyloaded\" src=\"https:\/\/flaven.fr\/wp-content\/uploads\/2024\/01\/open_interpreter_base_env_anaconda_small.png\" data-src=\"https:\/\/flaven.fr\/wp-content\/uploads\/2024\/01\/open_interpreter_base_env_anaconda_small.png\" alt=\"Using open-interpreter\" width=\"800\" height=\"520\"><\/p>\n<pre>\r\n  \"\"\"\r\n  [env]\r\n  # Conda Environment\r\n  conda create --name open_interpreter python=3.9.13\r\n  conda info --envs\r\n  source activate open_interpreter\r\n  conda deactivate\r\n  \r\n  # if needed to remove\r\n  conda env remove -n [NAME_OF_THE_CONDA_ENVIRONMENT]\r\n  conda env remove -n open_interpreter\r\n  \r\n  # update conda\r\n  conda update -n base -c defaults conda\r\n  \r\n  # to export requirements\r\n  pip freeze > requirements.txt\r\n  \r\n  # to install\r\n  pip install -r requirements.txt\r\n  \r\n  # [path]\r\n  \r\n  cd \/Users\/brunoflaven\/Documents\/01_work\/blog_articles\/ia_and_the_fake_prompt_academy\r\n  python 001_open_interpreter.py\r\n  \r\n  See https:\/\/docs.openinterpreter.com\/setup#python-usage\r\n  \r\n  - Installation\r\n  pip install open-interpreter\r\n  \r\n  \r\n  - Console or Terminal usage\r\n  interpreter\r\n  \r\n  \r\n  \"\"\"\r\n<\/pre>\n<p><H2>Commands to use interpreter<\/H2><\/p>\n<p>Below are the three possible ways to take advantage of open interpreter. Once again remember that you must have a ChatGPT API Key and that this can also possibly cost you a little money.<\/p>\n<p>For the ChatGPT API Key, check this resource:<br \/>\n<a href=\"https:\/\/platform.openai.com\/docs\/api-reference\/\" target=\"_blank\" rel=\"noopener\">https:\/\/platform.openai.com\/docs\/api-reference\/<\/a><\/p>\n<p><b>1. Using the classical way through the terminal<\/b><\/p>\n<pre>\r\n# Go to dir\r\ncd \/Users\/brunoflaven\/Documents\/01_work\/blog_articles\/ia_prompt_academy_project\/\r\n\r\n# Tip: To save this key for later, run export \r\n# OPENAI_API_KEY=your_api_key on Mac\/Linux or setx OPENAI_API_KEY your_api_key on Windows.\r\n\r\n# must-have\r\nexport OPENAI_API_KEY=sk-XXX-jkhjkhjkhjkh-FAKE-jkhjhXXX454423FCFG-FAKE-jk\r\n\r\n# Installation\r\npip install open-interpreter\r\n\r\n# Console or Terminal usage\r\ninterpreter\r\n\r\n# In the console, you can type the prompt\r\n# Prompt\r\nGive me 5 names for Italian cooking recipes?\r\n\r\n# output\r\nSure, here are 5 traditional Italian recipes:\r\n\r\n1 \"Pasta Carbonara\"                                            \r\n2 \"Lasagna alla Bolognese\"                                     \r\n3 \"Pasta Norma\"                                                \r\n4 \"Osso Buco alla Milanese\"                                    \r\n5 \"Risotto ai funghi porcini\"\r\n<\/pre>\n<pre>\r\n# to bypass message\r\n# Use interpreter -y to bypass this.\r\n\r\n# to get out\r\n# Press CTRL-C to exit.     \r\n<\/pre>\n<p><b>2. Combine with LM Studio<\/b><\/p>\n<p>It requires to have installed LM Studio. Let&#8217;s leverage on Code Llama or <code>(codellama)<\/code>, an LMM that has been trained specifically to write code. See below the description.<\/p>\n<blockquote><p>\nCode Llama is a model for generating and discussing code, built on top of Llama 2. It\u2019s designed to make workflows.<br \/>\nfaster and efficient for developers and make it easier for people to learn how to code. It can generate both code and<br \/>\nnatural language about code. Code Llama supports many of the most popular programming languages used today, including.<br \/>\nPython, C++, Java, PHP, Typescript (Javascript), C#, Bash and more.\n<\/p><\/blockquote>\n<p>You will need to run LM Studio in the background.<\/p>\n<p><blocquote><\/p>\n<ol>\n<li>Download https:\/\/lmstudio.ai\/ then start it.<\/li>\n<li>Select a model then click \u2193 Download.<\/li>\n<li>Click the &#x2194;&#xfe0f; button on the left (below &#x1f4ac;).<\/li>\n<li>Select your model at the top, then click Start Server.<\/li>\n<li>Once the server is running, you can begin your conversation with Open Interpreter.<\/li>\n<\/ol>\n<p><\/blocquote><\/p>\n<pre>\r\n# type in console\r\ninterpreter --local\r\n# you get the command above\r\n\r\n# prompt\r\nGive me 5 names for Italian cooking recipes?\r\n\r\n# output\r\n1 Lasagna\r\n2 Spaghetti Carbonara\r\n3 Penne Arrabiata\r\n4 Margherita pizza\r\n5 Fettuccine Alfredo\r\n<\/pre>\n<p><b>3. Combine with FastAPI<\/b><\/p>\n<p>It gives you the opportunity to integrate directly into FastAPI. You can check the example given in <code>002_open_interpreter.py<\/code><\/p>\n<pre>\r\n# Some examples prompts for interpreter\r\n\r\n- Can you set my system to dark mode?\r\n- Can you make a simple Pomodoro app?\r\n- Can you summarize the document \"\/Users\/brunoflaven\/Documents\/01_work\/blog_articles\/ia_and_the_fake_prompt_academy\/my_notebook_of_recipes_v1.docx\" and create a text file with it at the same path \"\/Users\/brunoflaven\/Documents\/01_work\/blog_articles\/ia_and_the_fake_prompt_academy\/my_notebook_of_recipes_v1.txt\"?\r\n- Can you list what is on my calendar?\r\n- Can you rename the file \"\/Users\/brunoflaven\/Documents\/01_work\/blog_articles\/ia_and_the_fake_prompt_academy\/264166941-37152071-680d-4423-9af3-64836a6f7b60.mp4\" with the following name \"\/Users\/brunoflaven\/Documents\/01_work\/blog_articles\/ia_and_the_fake_prompt_academy\/open_interpreter_commercial.mp4\"\r\n- Can you summarize the document \"\/Users\/brunoflaven\/Documents\/01_work\/blog_articles\/ia_and_the_fake_prompt_academy\/quotes_philosophy_v1.pdf\" and create a text file with it at the same path \"\/Users\/brunoflaven\/Documents\/01_work\/blog_articles\/ia_and_the_fake_prompt_academy\/quotes_philosophy_v1.txt\"?\r\n<\/pre>\n<h2>Other local tools for LLM<\/h2>\n<p>I made few test also on Mistral on LM Studio but also there are other tools for testing LMMs locally in addition to LM Studio or Ollama such as llama.cpp, KoboldCpp, llama-cpp-python but they are very geek-oriented.<\/p>\n<pre>\r\n# The LLMs used in LM Studio\r\n\r\n# Mixtral-8x7B-v0.1-GGUF\r\n# https:\/\/huggingface.co\/TheBloke\/Mixtral-8x7B-v0.1-GGUF\r\n\r\n# Mistral 7B Instruct v0.1 - GGUF\r\n# https:\/\/huggingface.co\/TheBloke\/Mistral-7B-Instruct-v0.1-GGUF\r\n\r\n<\/pre>\n<p><H2>More infos<\/H2><\/p>\n<ul>\n<li>Perplexity AI unlocks the power of knowledge&#8230; also a good alterntaive to ChatGPT<br \/><a href=\"https:\/\/www.perplexity.ai\/\" target=\"_blank\" rel=\"noopener\">https:\/\/www.perplexity.ai\/<\/a><\/li>\n<li>Extracting Text from PDF Files with Python: A Comprehensive Guide<br \/><a href=\"https:\/\/towardsdatascience.com\/extracting-text-from-pdf-files-with-python-a-comprehensive-guide-9fc4003d517\" target=\"_blank\" rel=\"noopener\">https:\/\/towardsdatascience.com\/extracting-text-from-pdf-files-with-python-a-comprehensive-guide-9fc4003d517<\/a>\n<\/li>\n<li>pdfplumber<br \/><a href=\"https:\/\/github.com\/jsvine\/pdfplumber\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/jsvine\/pdfplumber<\/a><\/li>\n<li>I tested how well ChatGPT can pull data out of messy PDFs (and here\u2019s a script so you can too)<br \/><a href=\"https:\/\/source.opennews.org\/articles\/testing-pdf-data-extraction-chatgpt\" target=\"_blank\" rel=\"noopener\">https:\/\/source.opennews.org\/articles\/testing-pdf-data-extraction-chatgpt<\/a><\/li>\n<li>Brandon Roberts, brandonrobertz \u00b7 he\/him<br \/><a href=\"https:\/\/github.com\/brandonrobertz\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/brandonrobertz<\/a><\/li>\n<li>JournalismAI Discovery<br \/><a href=\"https:\/\/www.journalismai.info\/programmes\/discovery\" target=\"_blank\" rel=\"noopener\">https:\/\/www.journalismai.info\/programmes\/discovery<\/a><\/li>\n<li>I tested how well ChatGPT can pull data out of messy PDFs (and here\u2019s a script so you can too)<br \/><a href=\"https:\/\/source.opennews.org\/articles\/testing-pdf-data-extraction-chatgpt\/\" target=\"_blank\" rel=\"noopener\">https:\/\/source.opennews.org\/articles\/testing-pdf-data-extraction-chatgpt\/<\/a><\/li>\n<li>Source from opennews.org<br \/><a href=\"https:\/\/source.opennews.org\/\" target=\"_blank\" rel=\"noopener\">https:\/\/source.opennews.org\/<\/a><\/li>\n<li>ChatGPT Data Extraction: A quick demonstration<br \/><a href=\"https:\/\/www.youtube.com\/watch?v=wsSqRv-y1r4\" target=\"_blank\" rel=\"noopener\">https:\/\/www.youtube.com\/watch?v=wsSqRv-y1r4<\/a><\/li>\n<li>Amazon Science on GitHub<br \/><a href=\"https:\/\/github.com\/amazon-science\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/amazon-science<\/a><\/li>\n<li>Llama.cpp Tutorial: A Complete Guide to Efficient LLM Inference and Implementation<br \/><a href=\"https:\/\/www.datacamp.com\/tutorial\/llama-cpp-tutorial\" target=\"_blank\" rel=\"noopener\">https:\/\/www.datacamp.com\/tutorial\/llama-cpp-tutorial<\/a><\/li>\n<li>Continue, the easiest way to code with any LLM<br \/><a href=\"https:\/\/continue.dev\/\" target=\"_blank\" rel=\"noopener\">https:\/\/continue.dev\/<\/a><\/li>\n<li>Open Interpreter on GitHub<br \/><a href=\"https:\/\/github.com\/KillianLucas\/open-interpreter\/#demo\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/KillianLucas\/open-interpreter\/#demo<\/a><\/li>\n<li>Getting Started with Open Interpreter<br \/><a href=\"https:\/\/docs.openinterpreter.com\/introduction\" target=\"_blank\" rel=\"noopener\">https:\/\/docs.openinterpreter.com\/introduction<\/a><\/li>\n<h3>Prompt Academy Resources<\/h3>\n<li>Prompt Engineering Guide<br \/><a href=\"https:\/\/github.com\/dair-ai\/Prompt-Engineering-Guide.git\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/dair-ai\/Prompt-Engineering-Guide.git<\/a><\/li>\n<li>All You Need to Know About Prompt Engineering<br \/><a href=\"https:\/\/www.educative.io\/courses\/all-you-need-to-know-about-prompt-engineering\" target=\"_blank\" rel=\"noopener\">https:\/\/www.educative.io\/courses\/all-you-need-to-know-about-prompt-engineering<\/a><\/li>\n<li>Introduction to Large Language Models<br \/><a href=\"https:\/\/developers.google.com\/machine-learning\/resources\/intro-llms\" target=\"_blank\" rel=\"noopener\">https:\/\/developers.google.com\/machine-learning\/resources\/intro-llms<\/a><\/li>\n<li>Prompting Introduction<br \/><a href=\"https:\/\/github.com\/dair-ai\/Prompt-Engineering-Guide\/blob\/main\/guides\/prompts-intro.md\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/dair-ai\/Prompt-Engineering-Guide\/blob\/main\/guides\/prompts-intro.md<\/a><\/li>\n<li>Prompt Engineering Guide<br \/><a href=\"https:\/\/github.com\/dair-ai\/Prompt-Engineering-Guide\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/dair-ai\/Prompt-Engineering-Guide<\/a><\/li>\n<li>DAIR.AI, Democratizing Artificial Intelligence Research, Education, and Technologies<br \/><a href=\"https:\/\/dair.ai\/posts\/\" target=\"_blank\" rel=\"noopener\">https:\/\/dair.ai\/posts\/<\/a><\/li>\n<li>DAIR.AI on GitHub<br \/><a href=\"https:\/\/github.com\/dair-ai\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/dair-ai<\/a><\/li>\n<li>Source Guides are collections of tutorials, project discussions, and advice on topics of interest to developers and<br \/>\ninteractive designers in newsrooms.<br \/><a href=\"https:\/\/source.opennews.org\/guides\/\" target=\"_blank\" rel=\"noopener\">https:\/\/source.opennews.org\/guides\/<\/a><\/li>\n<li>Prompt Engineering for LLMs<br \/><a href=\"https:\/\/maven.com\/dair-ai\/prompt-engineering-llms\" target=\"_blank\" rel=\"noopener\">https:\/\/maven.com\/dair-ai\/prompt-engineering-llms<\/a><\/li>\n<li>Docs from openai.com<br \/><a href=\"https:\/\/platform.openai.com\/docs\/overview\" target=\"_blank\" rel=\"noopener\">https:\/\/platform.openai.com\/docs\/overview<\/a><\/li>\n<h3>Journalist oriented tools<\/h3>\n<li>Statistical Claim Checking: StatCheck in Action<br \/><a href=\"https:\/\/www.youtube.com\/watch?v=C3L_aEy58o4\" target=\"_blank\" rel=\"noopener\">https:\/\/www.youtube.com\/watch?v=C3L_aEy58o4<\/a><\/li>\n<li>INRIA on GitHub<br \/><a href=\"https:\/\/github.com\/orgs\/INRIA\/repositories\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/orgs\/INRIA\/repositories<\/a><\/li>\n<li>Tineye<br \/><a href=\"https:\/\/tineye.com\/\" target=\"_blank\" rel=\"noopener\">https:\/\/tineye.com\/<\/a><\/li>\n<li>Pimeyes<br \/><a href=\"https:\/\/pimeyes.com\/en\" target=\"_blank\" rel=\"noopener\">https:\/\/pimeyes.com\/en<\/a><\/li>\n<li>geekflare.com<br \/><a href=\"https:\/\/geekflare.com\/reverse-image-search-tools\/\" target=\"_blank\" rel=\"noopener\">https:\/\/geekflare.com\/reverse-image-search-tools\/<\/a><\/li>\n<li>Invid-project<br \/><a href=\"https:\/\/www.invid-project.eu\/tools-and-services\/invid-verification-plugin\/\" target=\"_blank\" rel=\"noopener\">https:\/\/www.invid-project.eu\/tools-and-services\/invid-verification-plugin\/<\/a><\/li>\n<li>AFP-Medialab<br \/><a href=\"https:\/\/github.com\/orgs\/AFP-Medialab\/repositories\" target=\"_blank\" rel=\"noopener\">https:\/\/github.com\/orgs\/AFP-Medialab\/repositories<\/a><\/li>\n<li>Politifact<br \/><a href=\"https:\/\/www.politifact.com\/\" target=\"_blank\" rel=\"noopener\">https:\/\/www.politifact.com\/<\/a><\/li>\n<li>Statcheck<br \/><a href=\"https:\/\/team.inria.fr\/cedar\/projects\/statcheck\/\" target=\"_blank\" rel=\"noopener\">https:\/\/team.inria.fr\/cedar\/projects\/statcheck\/<\/a><\/li>\n<li>Deepware<br \/><a href=\"https:\/\/deepware.ai\/\" target=\"_blank\" rel=\"noopener\">https:\/\/deepware.ai\/<\/a><\/li>\n<li>Nunki<br \/><a href=\"https:\/\/www.nunki.co\/#solution\" target=\"_blank\" rel=\"noopener\">https:\/\/www.nunki.co\/#solution<\/a><\/li>\n<\/ul>\n",
            "protected": false
        },
        "excerpt": {
            "rendered": "<p>I am still digging on what can ease LLM querying in a confidential and secure way and at the same time, I am collecting stuff&hellip; <\/p>\n<p class=\"text-center\"><a href=\"https:\/\/flaven.fr\/2024\/01\/a-small-guide-to-harnessing-the-power-of-open-interpreter-and-unlocking-productivity-with-a-chatgpt-like-terminal-interface\/\" class=\"more-link\">Continue reading &rarr; <span class=\"screen-reader-text\">A small Guide to Harnessing the Power of Open Interpreter and Unlocking Productivity with a ChatGPT-Like Terminal Interface<\/span><\/a><\/p>\n",
            "protected": false
        },
        "author": 1
    }
]